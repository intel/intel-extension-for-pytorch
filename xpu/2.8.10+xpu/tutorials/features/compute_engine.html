

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Compute Engine (Experimental feature for debug) &mdash; Intel&amp;#174 Extension for PyTorch* 2.8.10+xpu documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=a95c1af4" />

  
<script type="text/javascript">
  // Configure TMS settings
  window.wapProfile = 'profile-microsite'; // This is mapped by WAP authorize value
  window.wapLocalCode = 'us-en'; // Dynamically set per localized site, see mapping table for values
  window.wapSection = "intel-extension-for-pytorch"; // WAP team will give you a unique section for your site
  window.wapEnv = 'prod'; // environment to be use in Adobe Tags.
  // Load TMS
  (() => {
        let url = 'https://www.intel.com/content/dam/www/global/wap/main/wap-microsite.js';
        let po = document.createElement('script'); po.type = 'text/javascript'; po.async = true; po.src = url;
        let s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(po, s);
  }) ();
</script>

    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="IPEX_LOG (Prototype)" href="ipex_log.html" />
    <link rel="prev" title="Kineto Profiler" href="profiler_kineto.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            Intel&#174 Extension for PyTorch*
          </a>
<div class="version">
            <a href="../../../../">2.8.10+xpu ▼</a>
            <p>Click link above to switch version</p>
          </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">ABOUT</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../introduction.html">Introduction</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../features.html">Features</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../features.html#easy-to-use-python-api">Easy-to-use Python API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../features.html#channels-last">Channels Last</a></li>
<li class="toctree-l2"><a class="reference internal" href="../features.html#auto-mixed-precision-amp">Auto Mixed Precision (AMP)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../features.html#quantization">Quantization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../features.html#distributed-training">Distributed Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="../features.html#dlpack-solution">DLPack Solution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../features.html#dpc-extension">DPC++ Extension</a></li>
<li class="toctree-l2"><a class="reference internal" href="../features.html#advanced-configuration">Advanced Configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../features.html#fully-sharded-data-parallel-fsdp">Fully Sharded Data Parallel (FSDP)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../features.html#torch-compile-for-gpu-beta">torch.compile for GPU (Beta)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../features.html#kineto-supported-profiler-tool-prototype">Kineto Supported Profiler Tool (Prototype)</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../features.html#compute-engine-prototype-feature-for-debug">Compute Engine (Prototype feature for debug)</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">Compute Engine (Experimental feature for debug)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="#use-case">Use Case</a></li>
<li class="toctree-l4"><a class="reference internal" href="#engine-selection-policy">Engine Selection Policy</a></li>
<li class="toctree-l4"><a class="reference internal" href="#multiple-implementations-operators-and-engines">Multiple Implementations Operators and Engines</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../features.html#ipex-log-prototype-feature-for-debug"><code class="docutils literal notranslate"><span class="pre">IPEX_LOG</span></code> (Prototype feature for debug)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../llm.html">Large Language Models (LLM)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../performance.html">Performance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../technical_details.html">Technical Details</a></li>
<li class="toctree-l1"><a class="reference internal" href="../releases.html">Releases</a></li>
<li class="toctree-l1"><a class="reference internal" href="../known_issues.html">Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference external" href="https://intel.github.io/intel-extension-for-pytorch/blogs.html">Blogs &amp; Publications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../license.html">License</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">GET STARTED</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://intel.github.io/intel-extension-for-pytorch/index.html#installation?platform=gpu&amp;version=v2.3.110%2bxpu">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples.html">Examples</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">DEVELOPER REFERENCE</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api_doc.html">API Documentation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">CONTRIBUTING GUIDE</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../contribution.html">Contribution</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Intel&#174 Extension for PyTorch*</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../features.html">Features</a></li>
      <li class="breadcrumb-item active">Compute Engine (Experimental feature for debug)</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/tutorials/features/compute_engine.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="compute-engine-experimental-feature-for-debug">
<h1>Compute Engine (Experimental feature for debug)<a class="headerlink" href="#compute-engine-experimental-feature-for-debug" title="Link to this heading"></a></h1>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Link to this heading"></a></h2>
<p>Compute engine provides the capacity to choose specific backend for operators with multiple implementations. For example, with compute engine set, we can prefer to using SYCL than oneDNN implementation for concatenation. The feature can help user to customize model forward behavior for better performance or special requirement.</p>
<p>We currently support 5 compute engines, namely, <code class="docutils literal notranslate"><span class="pre">RECOMMEND</span></code>, <code class="docutils literal notranslate"><span class="pre">BASIC</span></code>, <code class="docutils literal notranslate"><span class="pre">ONEDNN</span></code>, <code class="docutils literal notranslate"><span class="pre">ONEMKL</span></code>, <code class="docutils literal notranslate"><span class="pre">XETLA</span></code>. Each op with multiple implementations has a recommend one based on our empirical experience. The <code class="docutils literal notranslate"><span class="pre">RECOMMEND</span></code> engine would guarantee performance on most shape input ideally.  <code class="docutils literal notranslate"><span class="pre">BASIC</span></code> engines refers to SYCL implementation. <code class="docutils literal notranslate"><span class="pre">ONEDNN</span></code>, <code class="docutils literal notranslate"><span class="pre">ONEMKL</span></code> refers to optimized implementation provided by library <a class="reference external" href="https://github.com/oneapi-src/oneDNN">Intel® oneAPI Deep Neural Network Library (oneDNN)</a>, <a class="reference external" href="https://github.com/oneapi-src/oneMKL">Intel® oneAPI Math Kernel Library (oneMKL)</a>.</p>
</section>
<section id="use-case">
<h2>Use Case<a class="headerlink" href="#use-case" title="Link to this heading"></a></h2>
<p>Code snippet below demonstrates the usage of compute engine feature to select oneDNN as the compute engine of operator <code class="docutils literal notranslate"><span class="pre">torch.cat</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">xpu</span><span class="o">.</span><span class="n">compute_eng</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">xpu</span><span class="o">.</span><span class="n">XPUComputeEng</span><span class="o">.</span><span class="n">ONEDNN</span><span class="p">):</span>
    <span class="n">x1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;xpu&quot;</span><span class="p">)</span>
    <span class="n">x2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;xpu&quot;</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="engine-selection-policy">
<h2>Engine Selection Policy<a class="headerlink" href="#engine-selection-policy" title="Link to this heading"></a></h2>
<p>Generally, priority of choosing engine follows the order <code class="docutils literal notranslate"><span class="pre">operator</span> <span class="pre">special</span> <span class="pre">argument</span> <span class="pre">&gt;</span> <span class="pre">onednn_layout</span> <span class="pre">format</span> <span class="pre">input</span> <span class="pre">&gt;</span> <span class="pre">user</span> <span class="pre">set</span> <span class="pre">engine</span> <span class="pre">&gt;</span> <span class="pre">recommend</span> <span class="pre">engine</span></code>. Check the following for details:</p>
<p>Step 1: In some cases, operators with specific arguments may not have implementations for all compute engines. For these operators, the implemented compute engines have the highest priority in the selection process. For example, operator <code class="docutils literal notranslate"><span class="pre">torch.nn.Upsample</span></code> with argument <code class="docutils literal notranslate"><span class="pre">align_corners=True</span></code> has only SYCL implementation for GPU. Thus, the BASIC engine, referring to SYCL implementations, is always its computing engine.</p>
<p>Step2: If no special argument, and inputs contain <code class="docutils literal notranslate"><span class="pre">ONEDNN_LAYOUT</span></code> Tensor, <code class="docutils literal notranslate"><span class="pre">ONEDNN</span></code> engine would be chosen if possible. This would utilize the highly optimized code in library oneDNN to speedup computation.  If <code class="docutils literal notranslate"><span class="pre">oneDNN</span></code> has no support for the operator, engine selection process continues to next step.</p>
<p>Step3: If user manually set a engine, this engine is chosen once the operator supports this implementation.</p>
<p>Step4: If the compute engine designated by user is not implemented/available, execution of the operator will fall back on to the <code class="docutils literal notranslate"><span class="pre">RECOMMEND</span></code> engine.</p>
<p><img alt="fig-2(1)-pt-conv-layout-path-dispatch" src="../../_images/compute_eng_arc.png" /></p>
</section>
<section id="multiple-implementations-operators-and-engines">
<h2>Multiple Implementations Operators and Engines<a class="headerlink" href="#multiple-implementations-operators-and-engines" title="Link to this heading"></a></h2>
<p><code class="docutils literal notranslate"><span class="pre">AveragePool2d</span></code>: <code class="docutils literal notranslate"><span class="pre">ONEDNN</span></code>, <code class="docutils literal notranslate"><span class="pre">BASIC</span></code> [Recommend]</p>
<p><code class="docutils literal notranslate"><span class="pre">Concat</span></code>: <code class="docutils literal notranslate"><span class="pre">ONEDNN</span></code>, <code class="docutils literal notranslate"><span class="pre">BASIC</span></code> [Recommend]</p>
<p><code class="docutils literal notranslate"><span class="pre">MaxPool2d</span></code>, <code class="docutils literal notranslate"><span class="pre">MaxPool3d</span></code>: <code class="docutils literal notranslate"><span class="pre">ONEDNN</span></code>, <code class="docutils literal notranslate"><span class="pre">BASIC</span></code> [Recommend]</p>
<p><code class="docutils literal notranslate"><span class="pre">LSTM</span></code>: <code class="docutils literal notranslate"><span class="pre">ONEDNN</span></code>, <code class="docutils literal notranslate"><span class="pre">BASIC</span></code> [Recommend]</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Basic is recommended currently. When optimizations in oneDNN finish, `ONEDNN` would be the recommend engine.
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">LayerNorm</span></code>： <code class="docutils literal notranslate"><span class="pre">ONEDNN</span></code>, <code class="docutils literal notranslate"><span class="pre">BASIC</span></code> [Recommend]</p>
<p><code class="docutils literal notranslate"><span class="pre">PermuteContiguous</span></code>: <code class="docutils literal notranslate"><span class="pre">ONEDNN</span></code>, <code class="docutils literal notranslate"><span class="pre">BASIC</span></code> [Recommend]</p>
<p><code class="docutils literal notranslate"><span class="pre">SoftMax</span></code>: <code class="docutils literal notranslate"><span class="pre">ONEDNN</span></code>, <code class="docutils literal notranslate"><span class="pre">BASIC</span></code> [Recommend]</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>The `BASIC` engine is always chosen if input tensor has `dimension` greater than 3 or its `dtype` is other than `fp16, fp32` or `bfloat16`.
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">UpsampleBlinear2d</span></code>: <code class="docutils literal notranslate"><span class="pre">ONEDNN</span></code>, <code class="docutils literal notranslate"><span class="pre">BASIC</span></code> [Recommend]</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>The `BASIC` engine is always chosen if argument `align_corners=True`.
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">UpsampleNearest</span></code>: <code class="docutils literal notranslate"><span class="pre">ONEDNN</span></code>, <code class="docutils literal notranslate"><span class="pre">BASIC</span></code> [Recommend]</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>The `ONEDNN` engine is always chosen if output shape is divisible by the input shape.
</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="profiler_kineto.html" class="btn btn-neutral float-left" title="Kineto Profiler" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="ipex_log.html" class="btn btn-neutral float-right" title="IPEX_LOG (Prototype)" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   <jinja2.runtime.BlockReference object at 0x739385495060> 
<p></p><div><a href='https://www.intel.com/content/www/us/en/privacy/intel-cookie-notice.html' data-cookie-notice='true'>Cookies</a><a href='https://www.intel.com/content/www/us/en/privacy/intel-privacy-notice.html'>| Privacy</a><a href='/#' data-wap_ref='dns' id='wap_dns'><small>| Your Privacy Choices</small><span style='height:10px;width:28px;display:inline-block;position:relative;'><svg style='position:absolute;width:28px;bottom:-2px;' version='1.1' id='Layer_1' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' x='0px' y='0px' viewBox='0 0 30 14' xml:space='preserve'><title>California Consumer Privacy Act (CCPA) Opt-Out Icon</title><style type='text/css'> .st0 { fill-rule: evenodd; clip-rule: evenodd; fill: #FFFFFF; } .st1 { fill-rule: evenodd; clip-rule: evenodd; fill: #0066FF; } .st2 { fill: #FFFFFF; } .st3 { fill: #0066FF; } </style><g><g id='final---dec.11-2020_1_'><g id='_x30_208-our-toggle_2_' transform='translate(-1275.000000, -200.000000)'><g id='Final-Copy-2_2_' transform='translate(1275.000000, 200.000000)'><path class='st0' d='M7.4,12.8h6.8l3.1-11.6H7.4C4.2,1.2,1.6,3.8,1.6,7S4.2,12.8,7.4,12.8z'></path></g></g></g><g id='final---dec.11-2020'><g id='_x30_208-our-toggle' transform='translate(-1275.000000, -200.000000)'><g id='Final-Copy-2' transform='translate(1275.000000, 200.000000)'><path class='st1' d='M22.6,0H7.4c-3.9,0-7,3.1-7,7s3.1,7,7,7h15.2c3.9,0,7-3.1,7-7S26.4,0,22.6,0z M1.6,7c0-3.2,2.6-5.8,5.8-5.8 h9.9l-3.1,11.6H7.4C4.2,12.8,1.6,10.2,1.6,7z'></path><path id='x' class='st2' d='M24.6,4c0.2,0.2,0.2,0.6,0,0.8l0,0L22.5,7l2.2,2.2c0.2,0.2,0.2,0.6,0,0.8c-0.2,0.2-0.6,0.2-0.8,0 l0,0l-2.2-2.2L19.5,10c-0.2,0.2-0.6,0.2-0.8,0c-0.2-0.2-0.2-0.6,0-0.8l0,0L20.8,7l-2.2-2.2c-0.2-0.2-0.2-0.6,0-0.8 c0.2-0.2,0.6-0.2,0.8,0l0,0l2.2,2.2L23.8,4C24,3.8,24.4,3.8,24.6,4z'></path><path id='y' class='st3' d='M12.7,4.1c0.2,0.2,0.3,0.6,0.1,0.8l0,0L8.6,9.8C8.5,9.9,8.4,10,8.3,10c-0.2,0.1-0.5,0.1-0.7-0.1l0,0 L5.4,7.7c-0.2-0.2-0.2-0.6,0-0.8c0.2-0.2,0.6-0.2,0.8,0l0,0L8,8.6l3.8-4.5C12,3.9,12.4,3.9,12.7,4.1z'></path></g></g></g></g></svg></span></a><a href=https://www.intel.com/content/www/us/en/privacy/privacy-residents-certain-states.html data-wap_ref='nac' id='wap_nac'><small>| Notice at Collection</small></a></div><p></p><div>&copy; Intel Corporation. Intel, the Intel logo, and other Intel marks are trademarks of Intel Corporation or its subsidiaries. Other names and brands may be claimed as the property of others. No license (express or implied, by estoppel or otherwise) to any intellectual property rights is granted by this document, with the sole exception that code included in this document is licensed subject to the Zero-Clause BSD open source license (OBSD), <a href='http://opensource.org/licenses/0BSD'>http://opensource.org/licenses/0BSD</a>.</div>


</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>