<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Codeless Optimization (Experimental) &mdash; intel_extension_for_pytorch 1.13.0+cpu documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../_static/doctools.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Graph Capture (Experimental)" href="graph_capture.html" />
    <link rel="prev" title="INT8 Recipe Tuning API (Experimental)" href="int8_recipe_tuning_api.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> intel_extension_for_pytorch
          </a>
              <div class="version">
                <a href="../../../../versions.html">1.13.0+cpu ▼</a>
                <p>Click link above to switch version</p>
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../features.html">Features</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../features.html#ease-of-use-python-api">Ease-of-use Python API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../features.html#isa-dynamic-dispatching">ISA Dynamic Dispatching</a></li>
<li class="toctree-l2"><a class="reference internal" href="../features.html#auto-channels-last">Auto Channels Last</a></li>
<li class="toctree-l2"><a class="reference internal" href="../features.html#auto-mixed-precision-amp">Auto Mixed Precision (AMP)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../features.html#graph-optimization">Graph Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../features.html#operator-optimization">Operator Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../features.html#optimizer-optimization">Optimizer Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../features.html#runtime-extension">Runtime Extension</a></li>
<li class="toctree-l2"><a class="reference internal" href="../features.html#int8-quantization">INT8 Quantization</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../features.html#codeless-optimization-experimental-new-feature-in-1-13-0">Codeless Optimization (Experimental, <em>NEW feature in 1.13.0</em>)</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">Codeless Optimization (Experimental)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#motivation">Motivation</a></li>
<li class="toctree-l4"><a class="reference internal" href="#example-usage-with-huggingface">Example Usage with HuggingFace</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#the-origin-command-with-ipex-launch">The origin command with ipex launch</a></li>
<li class="toctree-l5"><a class="reference internal" href="#command-to-apply-ipex-optimization-for-fp32">Command to apply ipex optimization for FP32</a></li>
<li class="toctree-l5"><a class="reference internal" href="#command-to-apply-ipex-optimization-for-bf16">Command to apply ipex optimization for BF16</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#use-case-not-supported">Use Case not supported</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#module-uses-forward-method-explicitly-instead-of-the-call-attr">Module uses forward method explicitly instead of the <code class="docutils literal notranslate"><span class="pre">__call__</span></code> attr</a></li>
<li class="toctree-l5"><a class="reference internal" href="#already-using-ipex-optimize">Already using <code class="docutils literal notranslate"><span class="pre">ipex.optimize</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#already-using-jit-trace">Already using Jit Trace</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../features.html#graph-capture-experimental-new-feature-in-1-13-0">Graph Capture (Experimental, <em>NEW feature in 1.13.0</em>)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../features.html#hypertune-experimental-new-feature-in-1-13-0">HyperTune (Experimental, <em>NEW feature in 1.13.0</em>)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../releases.html">Releases</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../performance.html">Performance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_doc.html">API Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../performance_tuning.html">Performance Tuning Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../blogs_publications.html">Blogs &amp; Publications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contribution.html">Contribution</a></li>
<li class="toctree-l1"><a class="reference internal" href="../license.html">License</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">intel_extension_for_pytorch</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../features.html">Features</a> &raquo;</li>
      <li>Codeless Optimization (Experimental)</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/tutorials/features/codeless_optimization.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="codeless-optimization-experimental">
<h1>Codeless Optimization (Experimental)<a class="headerlink" href="#codeless-optimization-experimental" title="Permalink to this heading"></a></h1>
<p>This feature aims to get inference performance benefits from Intel® Extension for PyTorch* without changing code in your python scripts, which can raise Out-of-Box (OOB) experience to get started with Intel® Extension for PyTorch* easily. Users who already known how to apply optimizations with Intel® Extension for PyTorch* APIs are not targeted for this feature, due to the inevitable overhead and limitations we mentioned below.</p>
<section id="motivation">
<h2>Motivation<a class="headerlink" href="#motivation" title="Permalink to this heading"></a></h2>
<p>A typical use case of inference as in <a class="reference external" href="https://github.com/huggingface/transformers/blob/v4.21.1/src/transformers/trainer.py#L3187">transformer</a> can be simplified as the code snippet below:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">()</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="k">for</span> <span class="nb">input</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">():</span>
        <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<p>To utilize optimizations of Intel® Extension for PyTorch* for optimum performance, several lines code changes are required/recommended.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="n">impot</span> <span class="n">intel_extension_for_pytorch</span> <span class="k">as</span> <span class="n">ipex</span> <span class="c1"># clause added</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">()</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ipex</span><span class="o">.</span><span class="n">optimization</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>          <span class="c1"># clause added</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
  <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">cpu</span><span class="o">.</span><span class="n">amp</span><span class="o">.</span><span class="n">autocast</span><span class="p">():</span>          <span class="c1"># clause added for running with BFloat16 (Optional)</span>
    <span class="nb">input</span> <span class="o">=</span> <span class="o">...</span>                           <span class="c1"># clause added for TorchScript (Optional, but recommended) </span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>        <span class="c1"># clause added for TorchScript (Optional, but recommended) </span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">freeze</span><span class="p">()</span>            <span class="c1"># clause added for TorchScript (Optional, but recommended) </span>
    <span class="k">for</span> <span class="nb">input</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">():</span>
      <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<p>With this feature, code changes above done manually are not required any more. Intel® Extension for PyTorch* optimizations will be applied automatically during execution in a monkey patch way.</p>
<ul class="simple">
<li><p>Automatically import <code class="docutils literal notranslate"><span class="pre">intel_extension_for_pytorch</span></code> package: It applies Intel® Extension for PyTorch* optimizations, such as: <code class="docutils literal notranslate"><span class="pre">torch.embedding_bag</span></code>, <code class="docutils literal notranslate"><span class="pre">torch.cpu.amp.autocast</span></code>. It also registers Intel® Extension for PyTorch* JIT fusion pass and thus benefits the graph mode inference performance.</p></li>
<li><p>Automatically apply <code class="docutils literal notranslate"><span class="pre">ipex.optimize()</span></code> function. Only features enabled by default parameter values are supported, such as:</p>
<ul>
<li><p>Auto generate FX or Jit Graph.</p></li>
<li><p>Auto Channel Last convert.</p></li>
<li><p>Conv-Bn folding.</p></li>
<li><p>Weight prepack.</p></li>
<li><p>Replace dropout with identity.</p></li>
<li><p>Optimize LSTM.</p></li>
</ul>
</li>
<li><p>Automatically apply <code class="docutils literal notranslate"><span class="pre">torch.cpu.amp.autocast</span></code> with BFloat16 data type for inference.</p></li>
</ul>
</section>
<section id="example-usage-with-huggingface">
<h2>Example Usage with HuggingFace<a class="headerlink" href="#example-usage-with-huggingface" title="Permalink to this heading"></a></h2>
<p>Let’s take the <a class="reference external" href="https://github.com/huggingface/transformers/tree/main/examples/pytorch/question-answering">QA case</a> in HuggingFace as an example.</p>
<section id="the-origin-command-with-ipex-launch">
<h3>The origin command with ipex launch<a class="headerlink" href="#the-origin-command-with-ipex-launch" title="Permalink to this heading"></a></h3>
<p>Here is the command to run with <a class="reference internal" href="../performance_tuning/launch_script.html"><span class="doc">ipexrun</span></a>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">clear</span> <span class="o">&amp;&amp;</span> <span class="n">ipexrun</span> <span class="o">--</span><span class="n">use_default_allocator</span> <span class="o">--</span><span class="n">ninstance</span> <span class="mi">2</span> <span class="o">--</span><span class="n">ncore_per_instance</span> <span class="mi">28</span> <span class="n">run_qa</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">model_name_or_path</span> <span class="n">bert</span><span class="o">-</span><span class="n">base</span><span class="o">-</span><span class="n">uncased</span> <span class="o">--</span><span class="n">dataset_name</span> <span class="n">squad</span> <span class="o">--</span><span class="n">do_eval</span> <span class="o">--</span><span class="n">per_device_train_batch_size</span> <span class="mi">12</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">3e-5</span> <span class="o">--</span><span class="n">num_train_epochs</span> <span class="mi">2</span> <span class="o">--</span><span class="n">max_seq_length</span> <span class="mi">384</span> <span class="o">--</span><span class="n">doc_stride</span> <span class="mi">128</span> <span class="o">--</span><span class="n">output_dir</span> <span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">debug_squad</span><span class="o">/</span>
</pre></div>
</div>
</section>
<section id="command-to-apply-ipex-optimization-for-fp32">
<h3>Command to apply ipex optimization for FP32<a class="headerlink" href="#command-to-apply-ipex-optimization-for-fp32" title="Permalink to this heading"></a></h3>
<p>Added <code class="docutils literal notranslate"><span class="pre">--auto_ipex</span></code></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">clear</span> <span class="o">&amp;&amp;</span> <span class="n">ipexrun</span> <span class="o">--</span><span class="n">use_default_allocator</span> <span class="o">--</span><span class="n">ninstance</span> <span class="mi">2</span> <span class="o">--</span><span class="n">ncore_per_instance</span> <span class="mi">28</span> <span class="o">--</span><span class="n">auto_ipex</span> <span class="n">run_qa</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">model_name_or_path</span> <span class="n">bert</span><span class="o">-</span><span class="n">base</span><span class="o">-</span><span class="n">uncased</span> <span class="o">--</span><span class="n">dataset_name</span> <span class="n">squad</span> <span class="o">--</span><span class="n">do_eval</span> <span class="o">--</span><span class="n">per_device_train_batch_size</span> <span class="mi">12</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">3e-5</span> <span class="o">--</span><span class="n">num_train_epochs</span> <span class="mi">2</span> <span class="o">--</span><span class="n">max_seq_length</span> <span class="mi">384</span> <span class="o">--</span><span class="n">doc_stride</span> <span class="mi">128</span> <span class="o">--</span><span class="n">output_dir</span> <span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">debug_squad</span><span class="o">/</span>
</pre></div>
</div>
</section>
<section id="command-to-apply-ipex-optimization-for-bf16">
<h3>Command to apply ipex optimization for BF16<a class="headerlink" href="#command-to-apply-ipex-optimization-for-bf16" title="Permalink to this heading"></a></h3>
<p>Added <code class="docutils literal notranslate"><span class="pre">--auto_ipex</span> <span class="pre">--dtype</span> <span class="pre">bfloat16</span></code></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">clear</span> <span class="o">&amp;&amp;</span> <span class="n">ipexrun</span> <span class="o">--</span><span class="n">use_default_allocator</span> <span class="o">--</span><span class="n">ninstance</span> <span class="mi">2</span> <span class="o">--</span><span class="n">ncore_per_instance</span> <span class="mi">28</span> <span class="o">--</span><span class="n">auto_ipex</span> <span class="o">--</span><span class="n">dtype</span> <span class="n">bfloat16</span> <span class="n">run_qa</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">model_name_or_path</span> <span class="n">bert</span><span class="o">-</span><span class="n">base</span><span class="o">-</span><span class="n">uncased</span> <span class="o">--</span><span class="n">dataset_name</span> <span class="n">squad</span> <span class="o">--</span><span class="n">do_eval</span> <span class="o">--</span><span class="n">per_device_train_batch_size</span> <span class="mi">12</span> <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">3e-5</span> <span class="o">--</span><span class="n">num_train_epochs</span> <span class="mi">2</span> <span class="o">--</span><span class="n">max_seq_length</span> <span class="mi">384</span> <span class="o">--</span><span class="n">doc_stride</span> <span class="mi">128</span> <span class="o">--</span><span class="n">output_dir</span> <span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">debug_squad</span><span class="o">/</span>
</pre></div>
</div>
</section>
</section>
<section id="use-case-not-supported">
<h2>Use Case not supported<a class="headerlink" href="#use-case-not-supported" title="Permalink to this heading"></a></h2>
<section id="module-uses-forward-method-explicitly-instead-of-the-call-attr">
<h3>Module uses forward method explicitly instead of the <code class="docutils literal notranslate"><span class="pre">__call__</span></code> attr<a class="headerlink" href="#module-uses-forward-method-explicitly-instead-of-the-call-attr" title="Permalink to this heading"></a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="k">class</span> <span class="nc">DummyModule</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DummyModule</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">customized_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

<span class="c1"># Method1 will success</span>
<span class="n">DummyModule</span><span class="p">()(</span><span class="nb">input</span><span class="p">)</span>
<span class="c1"># Method2 will fail to apply ipex.optimize in the top-level model</span>
<span class="n">DummyModule</span><span class="p">()</span><span class="o">.</span><span class="n">customized_forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<p>If a model uses forward method explicitly instead of the <code class="docutils literal notranslate"><span class="pre">__call__</span></code> attr, we are unable to hook the execution of this model. As result, we are unable to auto apply the optimizations to this <code class="docutils literal notranslate"><span class="pre">DummyModule()</span></code>.</p>
</section>
<section id="already-using-ipex-optimize">
<h3>Already using <code class="docutils literal notranslate"><span class="pre">ipex.optimize</span></code><a class="headerlink" href="#already-using-ipex-optimize" title="Permalink to this heading"></a></h3>
<p>User already invokes <code class="docutils literal notranslate"><span class="pre">ipex.optimize</span></code> in script is not targeted for this feature. The behaviour as repeated invoking of <code class="docutils literal notranslate"><span class="pre">ipex.optimize</span></code> is not defined. The second invoking of <code class="docutils literal notranslate"><span class="pre">ipex.optimize</span></code> for the same module will fail with error message to avoid this behaviour.</p>
</section>
<section id="already-using-jit-trace">
<h3>Already using Jit Trace<a class="headerlink" href="#already-using-jit-trace" title="Permalink to this heading"></a></h3>
<p>For Jit trace case (as below example code) is not planned to support at first stage:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">()</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">traced_model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">traced_model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">freeze</span><span class="p">(</span><span class="n">traced_model</span><span class="p">)</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="k">for</span> <span class="nb">input</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">():</span>
        <span class="n">traced_model</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<p>For 2 reasons:</p>
<ul class="simple">
<li><p>The auto graph mode support has already been included in <code class="docutils literal notranslate"><span class="pre">ipex.optimize</span></code> with graph first API in 1.13.</p></li>
<li><p>Extra launch parameters and Monkey patches are needed to support above case. We will focus on the feasibility of first use case in TorchVision and HuggingFace workloads.</p></li>
</ul>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="int8_recipe_tuning_api.html" class="btn btn-neutral float-left" title="INT8 Recipe Tuning API (Experimental)" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="graph_capture.html" class="btn btn-neutral float-right" title="Graph Capture (Experimental)" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright Intel(R).</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>