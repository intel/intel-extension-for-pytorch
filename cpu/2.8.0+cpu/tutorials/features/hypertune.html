

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>HyperTune (Prototype) &mdash; Intel&amp;#174 Extension for PyTorch* 2.8.0+cpu documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=01a6a0bb" />

  
<script type="text/javascript">
  // Configure TMS settings
  window.wapProfile = 'profile-microsite'; // This is mapped by WAP authorize value
  window.wapLocalCode = 'us-en'; // Dynamically set per localized site, see mapping table for values
  window.wapSection = "intel-extension-for-pytorch"; // WAP team will give you a unique section for your site
  window.wapEnv = 'prod'; // environment to be use in Adobe Tags.
  // Load TMS
  (() => {
        let url = 'https://www.intel.com/content/dam/www/global/wap/main/wap-microsite.js';
        let po = document.createElement('script'); po.type = 'text/javascript'; po.async = true; po.src = url;
        let s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(po, s);
  }) ();
</script>

    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Fast BERT (Prototype)" href="fast_bert.html" />
    <link rel="prev" title="Graph Capture (Prototype)" href="graph_capture.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            Intel&#174 Extension for PyTorch*
          </a>
<div class="version">
            <a href="../../../../">2.8.0+cpu ▼</a>
            <p>Click link above to switch version</p>
          </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">ABOUT</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../introduction.html">Introduction</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../features.html">Features</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../features.html#easy-to-use-python-api">Easy-to-use Python API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../features.html#large-language-models-llm-new-feature-from-2-1-0">Large Language Models (LLM, <em>NEW feature from 2.1.0</em>)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../features.html#torch-compile-beta-new-feature-from-2-0-0">torch.compile (Beta, <em>NEW feature from 2.0.0</em>)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../features.html#isa-dynamic-dispatching">ISA Dynamic Dispatching</a></li>
<li class="toctree-l2"><a class="reference internal" href="../features.html#auto-channels-last">Auto Channels Last</a></li>
<li class="toctree-l2"><a class="reference internal" href="../features.html#auto-mixed-precision-amp">Auto Mixed Precision (AMP)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../features.html#graph-optimization">Graph Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../features.html#operator-optimization">Operator Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../features.html#runtime-extension">Runtime Extension</a></li>
<li class="toctree-l2"><a class="reference internal" href="../features.html#int8-quantization">INT8 Quantization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../features.html#codeless-optimization-prototype-new-feature-from-1-13-0">Codeless Optimization (Prototype, <em>NEW feature from 1.13.0</em>)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../features.html#graph-capture-prototype-new-feature-from-1-13-0">Graph Capture (Prototype, <em>NEW feature from 1.13.0</em>)</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../features.html#hypertune-prototype-new-feature-from-1-13-0">HyperTune (Prototype, <em>NEW feature from 1.13.0</em>)</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">HyperTune (Prototype)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#usage-of-hypertune">Usage of Hypertune</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#your-conf-file"><code class="docutils literal notranslate"><span class="pre">your_conf_file</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#hyperparameters">Hyperparameters</a><ul>
<li class="toctree-l6"><a class="reference internal" href="#launcher-hyperparameters">Launcher Hyperparameters</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="#defining-hyperparameters-and-their-search-spaces">Defining hyperparameters and their search spaces</a><ul>
<li class="toctree-l6"><a class="reference internal" href="#defining-hyperparameters-to-tune">1. Defining hyperparameters to tune:</a></li>
<li class="toctree-l6"><a class="reference internal" href="#defining-the-search-spaces-of-the-hyperparameters">2. Defining the search spaces of the hyperparameters:</a></li>
<li class="toctree-l6"><a class="reference internal" href="#default-search-space">Default search space</a></li>
<li class="toctree-l6"><a class="reference internal" href="#user-defined-search-space">User defined search space</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="#your-python-script"><code class="docutils literal notranslate"><span class="pre">&lt;your_python_script&gt;</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#usage-examples">Usage Examples</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../features.html#fast-bert-optimization-prototype-new-feature-from-2-0-0">Fast BERT Optimization (Prototype, <em>NEW feature from 2.0.0</em>)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../llm.html">Large Language Models (LLM)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../performance.html">Performance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../releases.html">Releases</a></li>
<li class="toctree-l1"><a class="reference internal" href="../known_issues.html">Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../blogs_publications.html">Blogs &amp; Publications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../license.html">License</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">GET STARTED</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cheat_sheet.html">Cheat Sheet</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">DEVELOPER REFERENCE</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api_doc.html">API Documentation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">PERFORMANCE TUNING</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../performance_tuning/tuning_guide.html">Performance Tuning Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../performance_tuning/launch_script.html">Launch Script Usage Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../performance_tuning/torchserve.html">TorchServe with Intel® Extension for PyTorch*</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">CONTRIBUTING GUIDE</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../contribution.html">Contribution</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Intel&#174 Extension for PyTorch*</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../features.html">Features</a></li>
      <li class="breadcrumb-item active">HyperTune (Prototype)</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/tutorials/features/hypertune.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="hypertune-prototype">
<h1>HyperTune (Prototype)<a class="headerlink" href="#hypertune-prototype" title="Link to this heading"></a></h1>
<p><img alt="HyperTune" src="../../_images/hypertune.png" /></p>
<p>HyperTune is an prototype feature to perform hyperparameter/execution configuration searching. The searching is used in various areas such as optimization of hyperparameters of deep learning models. The searching is extremely useful in real situations when the number of hyperparameters, including configuration of script execution, and their search spaces are huge that manually tuning these hyperparameters/configuration is impractical and time consuming. Hypertune automates this process of execution configuration searching for the <a class="reference internal" href="../performance_tuning/launch_script.html"><span class="doc">launcher</span></a> and Intel® Extension for PyTorch*.</p>
<section id="usage-of-hypertune">
<h2>Usage of Hypertune<a class="headerlink" href="#usage-of-hypertune" title="Link to this heading"></a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">intel_extension_for_pytorch</span><span class="o">.</span><span class="n">cpu</span><span class="o">.</span><span class="n">hypertune</span> <span class="o">--</span><span class="n">conf</span><span class="o">-</span><span class="n">file</span> <span class="o">&lt;</span><span class="n">your_conf_file</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">your_python_script</span><span class="o">&gt;</span> <span class="p">[</span><span class="n">args</span><span class="p">]</span>
</pre></div>
</div>
<p>There are two things to provide Hypertune (1) <code class="docutils literal notranslate"><span class="pre">&lt;your_conf_file&gt;</span></code> .yaml file to define the hyperparameters and their search spaces (2) <code class="docutils literal notranslate"><span class="pre">&lt;your_python_script&gt;</span></code> as an optimization function.</p>
<section id="your-conf-file">
<h3><code class="docutils literal notranslate"><span class="pre">your_conf_file</span></code><a class="headerlink" href="#your-conf-file" title="Link to this heading"></a></h3>
<p>The .yaml file is used to define configuration of Hypertune. There are two main information needed: (1) hyperparameters to tune and their search spaces (2) tuning strategy. See comments below together with a sample .yaml file.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tuning</span><span class="p">:</span>                                                        <span class="c1"># optional.</span>
  <span class="n">strategy</span><span class="p">:</span> <span class="n">grid</span>                                               <span class="c1"># optional. The tuning strategy. Default is grid. Must be one of {grid, random}.</span>
  <span class="n">max_trials</span><span class="p">:</span> <span class="mi">100</span>                                              <span class="c1"># optional. Allowed number of trials. Default is 100. If given time, set max_trials to product of length of all search spaces to try all possible combinations of hyperparameters.</span>

<span class="n">output_dir</span><span class="p">:</span> <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">saving</span><span class="o">/</span><span class="n">directory</span>                          <span class="c1"># optional. Directory to which the tuning history will be saved in record.csv file. Default is current working directory.</span>

<span class="n">hyperparams</span><span class="p">:</span>                                                   <span class="c1"># mandatory.</span>
  <span class="n">launcher</span><span class="p">:</span>                                                    <span class="c1"># optional.</span>
    <span class="n">hp</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;ncores_per_instance&#39;</span><span class="p">,</span> <span class="s1">&#39;ninstances&#39;</span><span class="p">]</span>                  <span class="c1"># mandatory. Mandatory if hyperparams.launcher is specified. Specify the launcher hyperparameters to tune.</span>
    <span class="n">ncores_per_instance</span><span class="p">:</span> <span class="n">all_physical_cores</span>                    <span class="c1"># optional.  Search space of ncores_per_instance if chosen to tune. If not defined, default search space of ncore_per_instance is used.</span>
    <span class="n">ninstances</span><span class="p">:</span>  <span class="p">[</span><span class="mi">1</span><span class="p">]</span>                                           <span class="c1"># optional.  Search space of ninstances if chosen to tune. If not defined, default search space of ninstances is used.</span>
</pre></div>
</div>
</section>
<section id="hyperparameters">
<h3>Hyperparameters<a class="headerlink" href="#hyperparameters" title="Link to this heading"></a></h3>
<section id="launcher-hyperparameters">
<h4>Launcher Hyperparameters<a class="headerlink" href="#launcher-hyperparameters" title="Link to this heading"></a></h4>
<p>Currently hypertune tunes for the following launcher hyperparameters:</p>
<table border="1" class="docutils">
<thead>
<tr>
<th style="text-align: left;">hyperparameter</th>
<th style="text-align: center;">default value</th>
<th style="text-align: center;">default search space</th>
<th style="text-align: center;">search space format</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><code>ncores_per_instance</code></td>
<td style="text-align: center;">-1</td>
<td style="text-align: center;"><code>all_logical_cores</code></td>
<td style="text-align: center;"><code>str or list of int. str must be one of {'all_logical_cores', 'all_physical_cores'}</code></td>
</tr>
<tr>
<td style="text-align: left;"><code>ninstances</code></td>
<td style="text-align: center;">-1</td>
<td style="text-align: center;"><code>all_logical_cores</code></td>
<td style="text-align: center;"><code>str or list of int. str must be one of {'all_logical_cores', 'all_physical_cores'}</code></td>
</tr>
<tr>
<td style="text-align: left;"><code>use_all_nodes</code></td>
<td style="text-align: center;">True</td>
<td style="text-align: center;"><code>[True, False] if num_nodes &gt; 1 else [True]</code></td>
<td style="text-align: center;"><code>list of bool</code></td>
</tr>
<tr>
<td style="text-align: left;"><code>use_logical_cores</code></td>
<td style="text-align: center;">False</td>
<td style="text-align: center;"><code>[True, False] if is_hyperthreading_enabled else [False]</code></td>
<td style="text-align: center;"><code>list of bool</code></td>
</tr>
<tr>
<td style="text-align: left;"><code>disable_numactl</code></td>
<td style="text-align: center;">False</td>
<td style="text-align: center;"><code>[True, False]</code></td>
<td style="text-align: center;"><code>list of bool</code></td>
</tr>
<tr>
<td style="text-align: left;"><code>disable_iomp</code></td>
<td style="text-align: center;">False</td>
<td style="text-align: center;"><code>[True, False]</code></td>
<td style="text-align: center;"><code>list of bool</code></td>
</tr>
<tr>
<td style="text-align: left;"><code>malloc</code></td>
<td style="text-align: center;">tc</td>
<td style="text-align: center;"><code>['tc', 'je', 'pt']</code></td>
<td style="text-align: center;"><code>list of str. str must be in {'tc', 'je', 'pt'}</code></td>
</tr>
</tbody>
</table></section>
</section>
<section id="defining-hyperparameters-and-their-search-spaces">
<h3>Defining hyperparameters and their search spaces<a class="headerlink" href="#defining-hyperparameters-and-their-search-spaces" title="Link to this heading"></a></h3>
<section id="defining-hyperparameters-to-tune">
<h4>1. Defining hyperparameters to tune:<a class="headerlink" href="#defining-hyperparameters-to-tune" title="Link to this heading"></a></h4>
<p>List the hyperparameters to tune in <code class="docutils literal notranslate"><span class="pre">hp</span></code>. For example, to tune all launcher hyperparameters:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hyperparams</span><span class="p">:</span>
  <span class="n">launcher</span><span class="p">:</span>
    <span class="n">hp</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;ncores_per_instance&#39;</span><span class="p">,</span> <span class="s1">&#39;ninstances&#39;</span><span class="p">,</span> <span class="s1">&#39;use_all_nodes&#39;</span><span class="p">,</span> <span class="s1">&#39;use_logical_cores&#39;</span><span class="p">,</span> <span class="s1">&#39;disable_numactl&#39;</span><span class="p">,</span> <span class="s1">&#39;disable_iomp&#39;</span><span class="p">,</span> <span class="s1">&#39;malloc&#39;</span><span class="p">]</span>
</pre></div>
</div>
<p>For example, to tune only launcher <code class="docutils literal notranslate"><span class="pre">ncores_per_instance</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hyperparams</span><span class="p">:</span>
  <span class="n">launcher</span><span class="p">:</span>
    <span class="n">hp</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;ncores_per_instance&#39;</span><span class="p">]</span>
</pre></div>
</div>
<p>All other launcher hyperparameters (<code class="docutils literal notranslate"><span class="pre">ninstances</span></code>, <code class="docutils literal notranslate"><span class="pre">use_all_nodes</span></code>, <code class="docutils literal notranslate"><span class="pre">use_logical_core</span></code>, <code class="docutils literal notranslate"><span class="pre">disable_numactl</span></code>, <code class="docutils literal notranslate"><span class="pre">disable_iomp</span></code>, <code class="docutils literal notranslate"><span class="pre">malloc</span></code>) will not be tuned and instead will use the default value defined in the previous section.</p>
</section>
<section id="defining-the-search-spaces-of-the-hyperparameters">
<h4>2. Defining the search spaces of the hyperparameters:<a class="headerlink" href="#defining-the-search-spaces-of-the-hyperparameters" title="Link to this heading"></a></h4>
</section>
<section id="default-search-space">
<h4>Default search space<a class="headerlink" href="#default-search-space" title="Link to this heading"></a></h4>
<p>If you don’t specify the search space of a hyperparamter, then the default search space defined in the previous section will be used for the hyperparameters defined in <code class="docutils literal notranslate"><span class="pre">hp</span></code>. For example,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hyperparams</span><span class="p">:</span>
  <span class="n">launcher</span><span class="p">:</span>
    <span class="n">hp</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;malloc&#39;</span><span class="p">]</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">malloc</span></code> will be tuned using its default search space, <code class="docutils literal notranslate"><span class="pre">['tc',</span> <span class="pre">'je',</span> <span class="pre">'pt']</span></code>. All other launcher hyperparamters (<code class="docutils literal notranslate"><span class="pre">ncores_per_instance</span></code>, <code class="docutils literal notranslate"><span class="pre">ninstances</span></code>, <code class="docutils literal notranslate"><span class="pre">use_all_nodes</span></code>, <code class="docutils literal notranslate"><span class="pre">use_logical_cores</span></code>, <code class="docutils literal notranslate"><span class="pre">disable_numactl</span></code>, <code class="docutils literal notranslate"><span class="pre">disable_iomp</span></code>) will not be tuned and instead will use their default values.</p>
</section>
<section id="user-defined-search-space">
<h4>User defined search space<a class="headerlink" href="#user-defined-search-space" title="Link to this heading"></a></h4>
<p>Specify the search space of a hyperparameter. For example,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hyperparams</span><span class="p">:</span>
  <span class="n">launcher</span><span class="p">:</span>
    <span class="n">hp</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;ncores_per_instance&#39;</span><span class="p">,</span> <span class="s1">&#39;ninstances&#39;</span><span class="p">,</span> <span class="s1">&#39;malloc&#39;</span><span class="p">]</span>
    <span class="n">ninstances</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">ncore_per_instance</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">]</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">ninstances</span></code> and <code class="docutils literal notranslate"><span class="pre">ncores_per_instance</span></code> will use user defined spaces <code class="docutils literal notranslate"><span class="pre">[1]</span></code> and <code class="docutils literal notranslate"><span class="pre">[1,</span> <span class="pre">2,</span> <span class="pre">3,</span> <span class="pre">4,</span> <span class="pre">5,</span> <span class="pre">6,</span> <span class="pre">7,</span> <span class="pre">8,</span> <span class="pre">9,</span> <span class="pre">10]</span></code> respectively. <code class="docutils literal notranslate"><span class="pre">malloc</span></code> will use its default search space, <code class="docutils literal notranslate"><span class="pre">['tc',</span> <span class="pre">'je',</span> <span class="pre">'pt']</span></code>.</p>
</section>
</section>
<section id="your-python-script">
<h3><code class="docutils literal notranslate"><span class="pre">&lt;your_python_script&gt;</span></code><a class="headerlink" href="#your-python-script" title="Link to this heading"></a></h3>
<p>This is the script as an optimization function.</p>
<ul class="simple">
<li><p>Step 1. Print the objective(s) you want to optimize. Make sure this is just an int or float to be minimized or maximized.</p></li>
<li><p>Step 2. Just before the objective(s), add print statement(s) of the <code class="docutils literal notranslate"><span class="pre">&#64;hypertune</span> <span class="pre">{'name':</span> <span class="pre">str,</span> <span class="pre">'higher_is_better':</span> <span class="pre">bool,</span> <span class="pre">'target_val':</span> <span class="pre">int</span> <span class="pre">or</span> <span class="pre">float}</span></code>.</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="s1">&#39;name&#39;</span>                                     <span class="c1"># mandatory. The name of your objective function.</span>
<span class="s1">&#39;higher_is_better&#39;</span>                         <span class="c1"># optional. True if objective function is to be maximized, False if to be minimized. Default is False.</span>
<span class="s1">&#39;target_val&#39;</span>                               <span class="c1"># optional. Target value of the objective function. Default is -float(&#39;inf&#39;)</span>
</pre></div>
</div>
<p>Have a look at the <a class="reference external" href="https://github.com/intel/intel-extension-for-pytorch/tree/v2.0.100+cpu/intel_extension_for_pytorch/cpu/hypertune/example/resnet50.py">example script</a>.</p>
</section>
</section>
<section id="usage-examples">
<h2>Usage Examples<a class="headerlink" href="#usage-examples" title="Link to this heading"></a></h2>
<p><strong>Tuning <code class="docutils literal notranslate"><span class="pre">ncores_per_instance</span></code> for minimum <code class="docutils literal notranslate"><span class="pre">latency</span></code></strong></p>
<p>Suppose we want to tune <code class="docutils literal notranslate"><span class="pre">ncores_per_instance</span></code> for a single instance to minimize latency for resnet50 on a machine with two Intel(R) Xeon(R) Platinum 8180M CPUs. Each socket has 28 physical cores and another 28 logical cores.</p>
<p>Run the following command with <a class="reference external" href="https://github.com/intel/intel-extension-for-pytorch/tree/v2.0.100+cpu/intel_extension_for_pytorch/cpu/hypertune/example/example.yaml">example.yaml</a> and <a class="reference external" href="https://github.com/intel/intel-extension-for-pytorch/tree/v2.0.100+cpu/intel_extension_for_pytorch/cpu/hypertune/example/resnet50.py">resnet50.py</a>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">intel_extension_for_pytorch</span><span class="o">.</span><span class="n">cpu</span><span class="o">.</span><span class="n">hypertune</span> <span class="o">--</span><span class="n">conf_file</span> <span class="o">&lt;</span><span class="n">hypertune_directory</span><span class="o">&gt;/</span><span class="n">example</span><span class="o">/</span><span class="n">example</span><span class="o">.</span><span class="n">yaml</span> <span class="o">&lt;</span><span class="n">hypertune_directory</span><span class="o">&gt;/</span><span class="n">example</span><span class="o">/</span><span class="n">resnet50</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
<p>Once search completes, it will print to terminal the best tune result and best tune configuration found. Below is an output for this example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Best</span> <span class="n">configuration</span> <span class="n">found</span> <span class="ow">is</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;ncores_per_instance&#39;</span><span class="p">:</span> <span class="mi">15</span><span class="p">,</span> <span class="s1">&#39;ninstances&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;use_all_nodes&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span> <span class="s1">&#39;use_logical_cores&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;disable_numactl&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;disable_iomp&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;malloc&#39;</span><span class="p">:</span> <span class="s1">&#39;tc&#39;</span><span class="p">}</span>
<span class="n">latency</span><span class="p">:</span> <span class="mf">12.339081764221191</span>
</pre></div>
</div>
<p>15 <code class="docutils literal notranslate"><span class="pre">ncores_per_instance</span></code> gave the minimum latency.</p>
<p>You will also find the tuning history in <code class="docutils literal notranslate"><span class="pre">&lt;output_dir&gt;/record.csv</span></code>. You can take <a class="reference external" href="https://github.com/intel/intel-extension-for-pytorch/tree/v2.0.100+cpu/intel_extension_for_pytorch/cpu/hypertune/example/record.csv">a sample csv file</a> as a reference.</p>
<p>Hypertune can also optimize multi-objective function. Add as many objectives as you would like to your script.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="graph_capture.html" class="btn btn-neutral float-left" title="Graph Capture (Prototype)" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="fast_bert.html" class="btn btn-neutral float-right" title="Fast BERT (Prototype)" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   <jinja2.runtime.BlockReference object at 0x7cbf91ace6e0> 
<p></p><div><a href='https://www.intel.com/content/www/us/en/privacy/intel-cookie-notice.html' data-cookie-notice='true'>Cookies</a><a href='https://www.intel.com/content/www/us/en/privacy/intel-privacy-notice.html'>| Privacy</a><a href='/#' data-wap_ref='dns' id='wap_dns'><small>| Your Privacy Choices</small><span style='height:10px;width:28px;display:inline-block;position:relative;'><svg style='position:absolute;width:28px;bottom:-2px;' version='1.1' id='Layer_1' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' x='0px' y='0px' viewBox='0 0 30 14' xml:space='preserve'><title>California Consumer Privacy Act (CCPA) Opt-Out Icon</title><style type='text/css'> .st0 { fill-rule: evenodd; clip-rule: evenodd; fill: #FFFFFF; } .st1 { fill-rule: evenodd; clip-rule: evenodd; fill: #0066FF; } .st2 { fill: #FFFFFF; } .st3 { fill: #0066FF; } </style><g><g id='final---dec.11-2020_1_'><g id='_x30_208-our-toggle_2_' transform='translate(-1275.000000, -200.000000)'><g id='Final-Copy-2_2_' transform='translate(1275.000000, 200.000000)'><path class='st0' d='M7.4,12.8h6.8l3.1-11.6H7.4C4.2,1.2,1.6,3.8,1.6,7S4.2,12.8,7.4,12.8z'></path></g></g></g><g id='final---dec.11-2020'><g id='_x30_208-our-toggle' transform='translate(-1275.000000, -200.000000)'><g id='Final-Copy-2' transform='translate(1275.000000, 200.000000)'><path class='st1' d='M22.6,0H7.4c-3.9,0-7,3.1-7,7s3.1,7,7,7h15.2c3.9,0,7-3.1,7-7S26.4,0,22.6,0z M1.6,7c0-3.2,2.6-5.8,5.8-5.8 h9.9l-3.1,11.6H7.4C4.2,12.8,1.6,10.2,1.6,7z'></path><path id='x' class='st2' d='M24.6,4c0.2,0.2,0.2,0.6,0,0.8l0,0L22.5,7l2.2,2.2c0.2,0.2,0.2,0.6,0,0.8c-0.2,0.2-0.6,0.2-0.8,0 l0,0l-2.2-2.2L19.5,10c-0.2,0.2-0.6,0.2-0.8,0c-0.2-0.2-0.2-0.6,0-0.8l0,0L20.8,7l-2.2-2.2c-0.2-0.2-0.2-0.6,0-0.8 c0.2-0.2,0.6-0.2,0.8,0l0,0l2.2,2.2L23.8,4C24,3.8,24.4,3.8,24.6,4z'></path><path id='y' class='st3' d='M12.7,4.1c0.2,0.2,0.3,0.6,0.1,0.8l0,0L8.6,9.8C8.5,9.9,8.4,10,8.3,10c-0.2,0.1-0.5,0.1-0.7-0.1l0,0 L5.4,7.7c-0.2-0.2-0.2-0.6,0-0.8c0.2-0.2,0.6-0.2,0.8,0l0,0L8,8.6l3.8-4.5C12,3.9,12.4,3.9,12.7,4.1z'></path></g></g></g></g></svg></span></a><a href=https://www.intel.com/content/www/us/en/privacy/privacy-residents-certain-states.html data-wap_ref='nac' id='wap_nac'><small>| Notice at Collection</small></a></div><p></p><div>&copy; Intel Corporation. Intel, the Intel logo, and other Intel marks are trademarks of Intel Corporation or its subsidiaries. Other names and brands may be claimed as the property of others. No license (express or implied, by estoppel or otherwise) to any intellectual property rights is granted by this document, with the sole exception that code included in this document is licensed subject to the Zero-Clause BSD open source license (OBSD), <a href='http://opensource.org/licenses/0BSD'>http://opensource.org/licenses/0BSD</a>.</div>


</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>