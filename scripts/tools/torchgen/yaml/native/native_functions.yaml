- func: geometric(Tensor(a) self, float p, *, Generator? generator=None) -> Tensor
  device_check: NoCheck   # TensorIterator
  tags: nondeterministic_seeded
  variants: function, method
  dispatch:
    XPU: geometric_xpu

- func: geometric.out(Tensor self, float p, *, Generator? generator=None, Tensor(a!) out) -> Tensor(a!)
  device_check: NoCheck   # TensorIterator
  tags: nondeterministic_seeded
  variants: function
  dispatch:
    XPU: geometric_out_xpu

- func: geometric_(Tensor(a!) self, float p, *, Generator? generator=None) -> Tensor(a!)
  device_check: NoCheck   # TensorIterator
  tags: nondeterministic_seeded
  variants: method
  dispatch:
    XPU: geometric_xpu_

- func: multilabel_margin_loss_backward.grad_input(Tensor grad_output, Tensor self, Tensor target, int reduction, Tensor is_target, *, Tensor(a!) grad_input) -> Tensor(a!)
  python_module: nn
  dispatch:
    XPU: multilabel_margin_loss_backward_out_xpu

- func: multilabel_margin_loss_backward(Tensor grad_output, Tensor self, Tensor target, int reduction, Tensor is_target) -> Tensor
  python_module: nn
  dispatch:
    XPU: multilabel_margin_loss_backward_xpu_

- func: multilabel_margin_loss_forward.output(Tensor self, Tensor target, int reduction, *, Tensor(a!) output, Tensor(b!) is_target) -> (Tensor(a!), Tensor(b!))
  python_module: nn
  dispatch:
    XPU: multilabel_margin_loss_forward_out_xpu_

- func: multilabel_margin_loss_forward(Tensor self, Tensor target, int reduction) -> (Tensor output, Tensor is_target)
  python_module: nn
  dispatch:
    XPU: multilabel_margin_loss_forward_xpu_

- func: _scaled_dot_product_efficient_attention(Tensor query, Tensor key, Tensor value, Tensor? attn_bias, bool compute_log_sumexp, float dropout_p=0.0, bool is_causal=False, *, float? scale=None) -> (Tensor output, Tensor log_sumexp, Tensor philox_seed, Tensor philox_offset)
  dispatch:
    XPU: _scaled_dot_product_efficient_attention_xpu
  tags: nondeterministic_seeded

- func: _scaled_dot_product_efficient_attention_backward(Tensor grad_out_, Tensor query, Tensor key, Tensor value, Tensor attn_bias, Tensor out, Tensor logsumexp, Tensor philox_seed, Tensor philox_offset, float dropout_p, bool[4] grad_input_mask, bool is_causal=False, *, float? scale=None) -> (Tensor, Tensor, Tensor, Tensor)
  device_check: NoCheck
  dispatch:
    XPU: _scaled_dot_product_efficient_attention_backward_xpu
  tags: nondeterministic_seeded

- func: _validate_compressed_sparse_indices(bool is_crow, Tensor compressed_idx, Tensor plain_idx, int cdim, int dim, int nnz) -> ()
  device_check: NoCheck
  variants: function
  dispatch:
    XPU: _validate_compressed_sparse_indices_xpu

- func: quantize_per_channel(Tensor self, Tensor scales, Tensor zero_points, int axis, ScalarType dtype) -> Tensor
  variants: function
  dispatch:
    XPU: quantize_per_channel_xpu
  autogen: quantize_per_channel.out

- func: quantize_per_tensor(Tensor self, float scale, int zero_point, ScalarType dtype) -> Tensor
  variants: function
  dispatch:
    XPU: quantize_per_tensor_xpu
  autogen: quantize_per_tensor.out

- func: quantize_per_tensor.tensor_qparams(Tensor self, Tensor scale, Tensor zero_point, ScalarType dtype) -> Tensor
  variants: function
  dispatch:
    XPU: quantize_per_tensor_tensor_qparams
  autogen: quantize_per_tensor.tensor_qparams_out

- func: quantize_per_tensor_dynamic(Tensor self, ScalarType dtype, bool reduce_range) -> Tensor
  variants: function
  dispatch:
    XPU: quantize_per_tensor_dynamic_xpu
  autogen: quantize_per_tensor_dynamic.out

- func: _make_per_channel_quantized_tensor(Tensor self, Tensor scale, Tensor zero_point, int axis) -> Tensor
  dispatch:
    XPU: make_per_channel_quantized_tensor_xpu
  autogen: _make_per_channel_quantized_tensor.out

- func: _make_per_tensor_quantized_tensor(Tensor self, float scale, int zero_point) -> Tensor
  dispatch:
    XPU: make_per_tensor_quantized_tensor_xpu
  autogen: _make_per_tensor_quantized_tensor.out

- func: _int_mm(Tensor self, Tensor mat2) -> Tensor
  dispatch:
    XPU: _int_mm_xpu_ipex

- func: pad_sequence(Tensor[] sequences, bool batch_first=False, float padding_value=0.0, str padding_side="right") -> Tensor
  python_module: nn
  variants: function
  dispatch:
    XPU: pad_sequence_xpu

- func: bmm(Tensor self, Tensor mat2) -> Tensor
  #  structured_delegate: bmm.out bmm.out is registered in pytorch
  variants: function, method
  dispatch:
    NestedTensorXPU: bmm_nested_xpu
  tags: core

# Temporarily reserved, and will be removed after merging https://github.com/intel/torch-xpu-ops/pull/1341
- func: _nested_from_padded(Tensor padded, Tensor cpu_nested_shape_example, bool fuse_transform_0213=False) -> Tensor
  device_check: NoCheck
  dispatch:
    XPU: _nested_from_padded_xpu
  autogen: _nested_from_padded.out

- func: _scaled_dot_product_attention_math(Tensor query, Tensor key, Tensor value, Tensor? attn_mask=None, float dropout_p=0.0, bool is_causal=False, Tensor? dropout_mask=None, *, float? scale=None, bool enable_gqa=False) -> (Tensor, Tensor)
  variants: function
  tags: nondeterministic_seeded
  dispatch:
    XPU: _scaled_dot_product_attention_math_xpu

- func: gru.input(Tensor input, Tensor hx, Tensor[] params, bool has_biases, int num_layers, float dropout, bool train, bool bidirectional, bool batch_first) -> (Tensor, Tensor)
  tags: nondeterministic_seeded
  dispatch:
    XPU: gru_xpu
