- func: geometric(Tensor(a) self, float p, *, Generator? generator=None) -> Tensor
  device_check: NoCheck   # TensorIterator
  tags: nondeterministic_seeded
  variants: function, method
  dispatch:
    XPU: geometric_xpu

- func: geometric.out(Tensor self, float p, *, Generator? generator=None, Tensor(a!) out) -> Tensor(a!)
  device_check: NoCheck   # TensorIterator
  tags: nondeterministic_seeded
  variants: function
  dispatch:
    XPU: geometric_out_xpu

- func: geometric_(Tensor(a!) self, float p, *, Generator? generator=None) -> Tensor(a!)
  device_check: NoCheck   # TensorIterator
  tags: nondeterministic_seeded
  variants: method
  dispatch:
    XPU: geometric_xpu_

- func: max_pool3d_with_indices.out(Tensor self, int[3] kernel_size, int[3] stride=[], int[3] padding=0, int[3] dilation=1, bool ceil_mode=False, *, Tensor(a!) out, Tensor(b!) indices) -> (Tensor(a!), Tensor(b!))
  python_module: nn
  dispatch:
    XPU: max_pool3d_with_indices_out_dpcpp

# Return: (Tensor output, Tensor indices)
- func: max_pool3d_with_indices(Tensor self, int[3] kernel_size, int[3] stride=[], int[3] padding=0, int[3] dilation=1, bool ceil_mode=False) -> (Tensor, Tensor)
  python_module: nn
  dispatch:
    XPU: max_pool3d_with_indices_dpcpp
  tags: core

- func: max_pool3d_with_indices_backward.grad_input(Tensor grad_output, Tensor self, int[3] kernel_size, int[3] stride, int[3] padding, int[3] dilation, bool ceil_mode, Tensor indices, *, Tensor(a!) grad_input) -> Tensor(a!)
  python_module: nn
  dispatch:
    XPU: max_pool3d_with_indices_backward_out_dpcpp

- func: max_pool3d_with_indices_backward(Tensor grad_output, Tensor self, int[3] kernel_size, int[3] stride, int[3] padding, int[3] dilation, bool ceil_mode, Tensor indices) -> Tensor
  python_module: nn
  dispatch:
    XPU: max_pool3d_with_indices_backward_dpcpp

- func: max_unpool2d.out(Tensor self, Tensor indices, SymInt[2] output_size, *, Tensor(a!) out) -> Tensor(a!)
  python_module: nn
  dispatch:
    XPU: max_unpooling2d_forward_out_dpcpp

- func: max_unpool2d(Tensor self, Tensor indices, SymInt[2] output_size) -> Tensor
  python_module: nn
  dispatch:
    XPU: max_unpooling2d_forward_dpcpp

- func: max_unpool3d.out(Tensor self, Tensor indices, SymInt[3] output_size, int[3] stride, int[3] padding, *, Tensor(a!) out) -> Tensor(a!)
  python_module: nn
  dispatch:
    XPU: max_unpooling3d_forward_out_dpcpp

- func: max_unpool3d(Tensor self, Tensor indices, SymInt[3] output_size, int[3] stride, int[3] padding) -> Tensor
  python_module: nn
  dispatch:
    XPU: max_unpooling3d_forward_dpcpp

- func: multilabel_margin_loss_backward.grad_input(Tensor grad_output, Tensor self, Tensor target, int reduction, Tensor is_target, *, Tensor(a!) grad_input) -> Tensor(a!)
  python_module: nn
  dispatch:
    XPU: multilabel_margin_loss_backward_out_xpu

- func: multilabel_margin_loss_backward(Tensor grad_output, Tensor self, Tensor target, int reduction, Tensor is_target) -> Tensor
  python_module: nn
  dispatch:
    XPU: multilabel_margin_loss_backward_xpu

- func: multilabel_margin_loss_forward.output(Tensor self, Tensor target, int reduction, *, Tensor(a!) output, Tensor(b!) is_target) -> (Tensor(a!), Tensor(b!))
  python_module: nn
  dispatch:
    XPU: multilabel_margin_loss_forward_out_xpu

- func: multilabel_margin_loss_forward(Tensor self, Tensor target, int reduction) -> (Tensor output, Tensor is_target)
  python_module: nn
  dispatch:
    XPU: multilabel_margin_loss_forward_xpu

- func: _linalg_det(Tensor A) -> (Tensor result, Tensor LU, Tensor pivots)
  structured_delegate: _linalg_det.result

- func: _linalg_det.result(Tensor A, *, Tensor(a!) result, Tensor(b!) LU, Tensor(c!) pivots) -> (Tensor(a!) result, Tensor(b!) LU, Tensor(c!) pivots)
  structured: True
  dispatch:
    XPU: _linalg_det_out_xpu

- func: _linalg_slogdet(Tensor A) -> (Tensor sign, Tensor logabsdet, Tensor LU, Tensor pivots)
  structured_delegate: _linalg_slogdet.sign

- func: _linalg_slogdet.sign(Tensor A, *, Tensor(a!) sign, Tensor(b!) logabsdet, Tensor(c!) LU, Tensor(d!) pivots) -> (Tensor(a!) sign, Tensor(b!) logabsdet, Tensor(c!) LU, Tensor(d!) pivots)
  structured: True
  dispatch:
    XPU: _linalg_slogdet_out_xpu

- func: _scaled_dot_product_efficient_attention(Tensor query, Tensor key, Tensor value, Tensor? attn_bias, bool compute_log_sumexp, float dropout_p=0.0, bool is_causal=False, *, float? scale=None) -> (Tensor output, Tensor log_sumexp, Tensor philox_seed, Tensor philox_offset)
  dispatch:
    XPU: _scaled_dot_product_efficient_attention_xpu
  tags: nondeterministic_seeded

- func: _scaled_dot_product_efficient_attention_backward(Tensor grad_out_, Tensor query, Tensor key, Tensor value, Tensor attn_bias, Tensor out, Tensor logsumexp, Tensor philox_seed, Tensor philox_offset, float dropout_p, bool[4] grad_input_mask, bool is_causal=False, *, float? scale=None) -> (Tensor, Tensor, Tensor, Tensor)
  device_check: NoCheck
  dispatch:
    XPU: _scaled_dot_product_efficient_attention_backward_xpu
  tags: nondeterministic_seeded

- func: _validate_compressed_sparse_indices(bool is_crow, Tensor compressed_idx, Tensor plain_idx, int cdim, int dim, int nnz) -> ()
  device_check: NoCheck
  variants: function
  dispatch:
    XPU: _validate_compressed_sparse_indices_xpu

- func: linalg_eigvals(Tensor self) -> Tensor
  python_module: linalg

- func: linalg_eigvals.out(Tensor self, *, Tensor(a!) out) -> Tensor(a!)
  python_module: linalg
  dispatch:
    XPU: linalg_eigvals_out

- func: quantize_per_channel(Tensor self, Tensor scales, Tensor zero_points, int axis, ScalarType dtype) -> Tensor
  variants: function
  dispatch:
    XPU: quantize_per_channel_xpu
  autogen: quantize_per_channel.out

- func: quantize_per_tensor(Tensor self, float scale, int zero_point, ScalarType dtype) -> Tensor
  variants: function
  dispatch:
    XPU: quantize_per_tensor_xpu
  autogen: quantize_per_tensor.out

- func: quantize_per_tensor.tensor_qparams(Tensor self, Tensor scale, Tensor zero_point, ScalarType dtype) -> Tensor
  variants: function
  dispatch:
    XPU: quantize_per_tensor_tensor_qparams
  autogen: quantize_per_tensor.tensor_qparams_out

- func: quantize_per_tensor_dynamic(Tensor self, ScalarType dtype, bool reduce_range) -> Tensor
  variants: function
  dispatch:
    XPU: quantize_per_tensor_dynamic_xpu
  autogen: quantize_per_tensor_dynamic.out

- func: _make_per_channel_quantized_tensor(Tensor self, Tensor scale, Tensor zero_point, int axis) -> Tensor
  dispatch:
    XPU: make_per_channel_quantized_tensor_xpu
  autogen: _make_per_channel_quantized_tensor.out

- func: _make_per_tensor_quantized_tensor(Tensor self, float scale, int zero_point) -> Tensor
  dispatch:
    XPU: make_per_tensor_quantized_tensor_xpu
  autogen: _make_per_tensor_quantized_tensor.out

- func: _int_mm(Tensor self, Tensor mat2) -> Tensor
  dispatch:
    XPU: _int_mm_xpu

- func: pad_sequence(Tensor[] sequences, bool batch_first=False, float padding_value=0.0, str padding_side="right") -> Tensor
  python_module: nn
  variants: function
  dispatch:
    XPU: pad_sequence_xpu

- func: bmm(Tensor self, Tensor mat2) -> Tensor
  #  structured_delegate: bmm.out bmm.out is registered in pytorch
  variants: function, method
  dispatch:
    NestedTensorXPU: bmm_nested_xpu
  tags: core

# Temporarily reserved, and will be removed after merging https://github.com/intel/torch-xpu-ops/pull/1341
- func: _nested_from_padded(Tensor padded, Tensor cpu_nested_shape_example, bool fuse_transform_0213=False) -> Tensor
  device_check: NoCheck
  dispatch:
    XPU: _nested_from_padded_xpu
  autogen: _nested_from_padded.out

- func: _scaled_dot_product_attention_math(Tensor query, Tensor key, Tensor value, Tensor? attn_mask=None, float dropout_p=0.0, bool is_causal=False, Tensor? dropout_mask=None, *, float? scale=None, bool enable_gqa=False) -> (Tensor, Tensor)
  variants: function
  tags: nondeterministic_seeded
  dispatch:
    XPU: _scaled_dot_product_attention_math_xpu

- func: gru.input(Tensor input, Tensor hx, Tensor[] params, bool has_biases, int num_layers, float dropout, bool train, bool bidirectional, bool batch_first) -> (Tensor, Tensor)
  tags: nondeterministic_seeded
  dispatch:
    XPU: gru_xpu
