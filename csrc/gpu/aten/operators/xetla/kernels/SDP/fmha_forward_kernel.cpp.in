
/*
Fused Multi-Head Attention Forward

This is an implementation of the Flash Attention algorithm
(see: Dao et al., https://arxiv.org/pdf/2205.14135v2.pdf)
*/

#include "SDP/fmha_forward.hpp"
#include "SDP/fmha_forward_kernel.hpp"
#include "SDP/fmha_forward_v2.hpp"
#include "SDP/fmha_forward_v3.hpp"
#include "SDP/fmha_forward_v4.hpp"

// clang-format off
// macros to be filled in CMake
#define IMPL_T ${IMPL_T}
#define IMPL_ARCH_TAG gpu_arch::${IMPL_ARCH_TAG}
#define GPU_ARCH_${IMPL_ARCH_TAG}
#cmakedefine01 IMPL_KUSEALIBI
#cmakedefine01 IMPL_KUSEBIAS
#cmakedefine01 IMPL_KISCAUSAL
#cmakedefine01 IMPL_KSEQLAST
#cmakedefine01 IMPL_KISTRAINING
#cmakedefine01 IMPL_KISDROPOUT
#cmakedefine01 IMPL_KISVARLEN
#cmakedefine01 IMPL_KISLOCAL
// clang-format on

#define LAUNCH_V4_KERNEL_IMPL(kHeadPerKv)                                      \
  do {                                                                         \
    static constexpr uint32_t sg_num = (kHeadPerKv * fmha_policy::kHm >= 1024) \
        ? arch_attr_t<arch_tag>::thread_per_wg / 2                             \
        : arch_attr_t<arch_tag>::thread_per_wg;                                \
    using fmha_forward_op_t =                                                  \
        fmha_forward_v4_t<T, arch_tag, sg_num, fmha_policy::kHm, kHeadPerKv>;  \
                                                                               \
    sycl::nd_range<3> NdRange =                                                \
        fmha_forward_op_t::get_nd_range(args.num_batches, args.num_kv_heads);  \
                                                                               \
    FmhaForwardKernelFunctor<fmha_forward_op_t, T, false, true> kfn(args);     \
                                                                               \
    return {[=](sycl::handler& cgh) { cgh.parallel_for(NdRange, kfn); }};      \
  } while (0)

#define LAUNCH_V3_KERNEL_IMPL(kHeadPerKv)                                 \
  do {                                                                    \
    using fmha_forward_op_t = fmha_forward_v3_t<                          \
        fmha_policy,                                                      \
        T,                                                                \
        arch_tag,                                                         \
        kUseAlibi,                                                        \
        kUseBias,                                                         \
        kIsCausal,                                                        \
        kSeqLast,                                                         \
        kIsTraining,                                                      \
        kIsDropout,                                                       \
        kVarlen,                                                          \
        kIsLocal,                                                         \
        kHeadPerKv>;                                                      \
                                                                          \
    sycl::nd_range<3> NdRange = fmha_forward_op_t::get_nd_range(          \
        args.num_batches * args.num_kv_heads, args.num_queries);          \
                                                                          \
    FmhaForwardKernelFunctor<fmha_forward_op_t, T, kUseV2> kfn(args);     \
                                                                          \
    return {[=](sycl::handler& cgh) { cgh.parallel_for(NdRange, kfn); }}; \
  } while (0)

namespace gpu::xetla {

namespace fmha {

template <typename fmha_policy>
struct is_fmha_v2 : std::false_type {};

template <int head_dim>
struct is_fmha_v2<std::integral_constant<int, head_dim>> : std::true_type {};

// The launcher of fmha forward kernel
template <
    typename fmha_policy,
    typename T,
    gpu_arch arch_tag,
    bool kUseAlibi,
    bool kUseBias,
    bool kIsCausal,
    bool kSeqLast,
    bool kIsTraining,
    bool kIsDropout,
    bool kVarlen,
    bool kIsLocal>
cgfs_t xetla_fmha_forward_kernel(const dispatch_fmha_forward_args_t<T>& args) {
#ifdef SDP_DBG
  printf(
      "Use_v2: %b, B, N, Nkv, F, T, H: %u, %u, %u, %u, %u, %u, UseAlibi: %d, UseBias: %d, IsCausal: %d, IsTraining: %d,"
      "IsDropout: %d, IsVarlen: %d, IsLocal: %d, alibi @ 0x%llx, uAT %d, uMT %d, strideB %d, strideN %d, strideF %d, dropout_prob %f, kSeqLast %d\n",
      is_fmha_v2<fmha_policy>::value,
      args.num_batches,
      args.num_heads,
      args.num_kv_heads,
      args.num_queries,
      args.num_keys,
      args.head_size,
      kUseAlibi,
      kUseBias,
      kIsCausal,
      kIsTraining,
      kIsDropout,
      kVarlen,
      kIsLocal,
      (unsigned long long)args.alibi,
      args.alibi_padded_block_size,
      args.attn_mask_padded_block_size,
      args.bias_strideB,
      args.bias_strideN,
      args.bias_strideF,
      args.dropout_prob,
      kSeqLast);
#endif

  constexpr bool kUseV2 = is_fmha_v2<fmha_policy>::value;
  // fmha forward kernel

  if constexpr (!kUseV2) {
    if constexpr (
        std::is_same_v<fmha_policy, fmha_policy_1x64x64> ||
        std::is_same_v<fmha_policy, fmha_policy_1x128x64> ||
        std::is_same_v<fmha_policy, fmha_policy_1x64x128> ||
        std::is_same_v<fmha_policy, fmha_policy_1x128x128>) {
      // current 16xXXX policy will stuck on some shapes
      // std::is_same_v<fmha_policy, fmha_policy_16x64x64> ||
      // std::is_same_v<fmha_policy, fmha_policy_16x128x64> ||
      // std::is_same_v<fmha_policy, fmha_policy_16x64x128> ||
      // std::is_same_v<fmha_policy, fmha_policy_16x128x128>
      auto kHeadPerKv = args.num_heads / args.num_kv_heads;
      switch (kHeadPerKv) {
        case 1:
          LAUNCH_V3_KERNEL_IMPL(1);
        case 2:
          LAUNCH_V3_KERNEL_IMPL(2);
        case 3:
          LAUNCH_V3_KERNEL_IMPL(3);
        case 4:
          LAUNCH_V3_KERNEL_IMPL(4);
        case 5:
          LAUNCH_V3_KERNEL_IMPL(5);
        case 6:
          LAUNCH_V3_KERNEL_IMPL(6);
        case 7:
          LAUNCH_V3_KERNEL_IMPL(7);
        case 8:
          LAUNCH_V3_KERNEL_IMPL(8);
        default: {
          throw std::runtime_error("Unsupported kHeadPerKv value");
        }
      }
    } else if constexpr (
        std::is_same_v<fmha_policy, fmha_policy_v4_64> ||
        std::is_same_v<fmha_policy, fmha_policy_v4_64>) {
      auto kHeadPerKv = args.num_heads / args.num_kv_heads;
      switch (kHeadPerKv) {
        case 1:
          LAUNCH_V4_KERNEL_IMPL(1);
        case 2:
          LAUNCH_V4_KERNEL_IMPL(2);
        case 3:
          LAUNCH_V4_KERNEL_IMPL(3);
        case 4:
          LAUNCH_V4_KERNEL_IMPL(4);
        case 5:
          LAUNCH_V4_KERNEL_IMPL(5);
        case 6:
          LAUNCH_V4_KERNEL_IMPL(6);
        case 7:
          LAUNCH_V4_KERNEL_IMPL(7);
        case 8:
          LAUNCH_V4_KERNEL_IMPL(8);
        default: {
          throw std::runtime_error("Unsupported kHeadPerKv value");
        }
      }
    } else {
      using fmha_forward_op_t = fmha_forward_t<
          fmha_policy,
          T,
          arch_tag,
          kUseAlibi,
          kUseBias,
          kIsCausal,
          kSeqLast,
          kIsTraining,
          kIsDropout,
          kVarlen,
          kIsLocal>;

      sycl::nd_range<3> NdRange = fmha_forward_op_t::get_nd_range(
          args.num_batches * args.num_heads, args.num_queries);

      FmhaForwardKernelFunctor<fmha_forward_op_t, T, kUseV2> kfn(args);
      return {[=](sycl::handler& cgh) { cgh.parallel_for(NdRange, kfn); }};
    }
  } else {
    static constexpr uint32_t sg_num = arch_attr_t<arch_tag>::thread_per_wg;
    using fmha_forward_op_t =
        fmha_forward_v2_t<T, arch_tag, sg_num, fmha_policy::value, kUseBias>;

    sycl::nd_range<3> NdRange =
        fmha_forward_op_t::get_nd_range(args.num_batches, args.num_heads);

    FmhaForwardKernelFunctor<fmha_forward_op_t, T, kUseV2> kfn(args);
    return {[=](sycl::handler& cgh) { cgh.parallel_for(NdRange, kfn); }};
  }
}

#define INSTANTIATE_POLICY(policy)           \
  template cgfs_t xetla_fmha_forward_kernel< \
      policy,                                \
      IMPL_T,                                \
      IMPL_ARCH_TAG,                         \
      IMPL_KUSEALIBI,                        \
      IMPL_KUSEBIAS,                         \
      IMPL_KISCAUSAL,                        \
      IMPL_KSEQLAST,                         \
      IMPL_KISTRAINING,                      \
      IMPL_KISDROPOUT,                       \
      IMPL_KISVARLEN,                        \
      IMPL_KISLOCAL>(const dispatch_fmha_forward_args_t<IMPL_T>& args)

#if (IMPL_KISTRAINING && IMPL_KISDROPOUT && defined(GPU_ARCH_XeHpc))
INSTANTIATE_POLICY(fmha_policy_128x128x64);
INSTANTIATE_POLICY(fmha_policy_128x128x128);
INSTANTIATE_POLICY(fmha_policy_128x128x256);
INSTANTIATE_POLICY(fmha_policy_64x128x512);
#endif

// chunked prefill policy support only pvc now
#if defined(GPU_ARCH_XeHpc)
INSTANTIATE_POLICY(fmha_policy_1x64x64);
INSTANTIATE_POLICY(fmha_policy_1x64x128);
INSTANTIATE_POLICY(fmha_policy_1x128x64);
INSTANTIATE_POLICY(fmha_policy_1x128x128);
INSTANTIATE_POLICY(fmha_policy_v4_64);
INSTANTIATE_POLICY(fmha_policy_v4_128);
INSTANTIATE_POLICY(fmha_policy_64x64x64);
INSTANTIATE_POLICY(fmha_policy_64x64x128);
INSTANTIATE_POLICY(fmha_policy_64x64x256);
INSTANTIATE_POLICY(fmha_policy_64x64x512);
#endif

INSTANTIATE_POLICY(fmha_policy_8x128x64);
INSTANTIATE_POLICY(fmha_policy_64x128x64);

#if (!IMPL_KISDROPOUT && defined(GPU_ARCH_XeLpg))
#define COMMA ,
INSTANTIATE_POLICY(fmha_policy_1x256x128);
INSTANTIATE_POLICY(fmha_policy_1x512x128);
INSTANTIATE_POLICY(std::integral_constant<int COMMA 64>);
INSTANTIATE_POLICY(std::integral_constant<int COMMA 128>);
#endif

INSTANTIATE_POLICY(fmha_policy_8x256x128);
INSTANTIATE_POLICY(fmha_policy_8x512x128);

#if defined(GPU_ARCH_XeLpg)
INSTANTIATE_POLICY(fmha_policy_32x128x128);
#else
INSTANTIATE_POLICY(fmha_policy_64x128x128);
#endif

#if defined(GPU_ARCH_XeLpg)
#else
INSTANTIATE_POLICY(fmha_policy_8x256x256);
INSTANTIATE_POLICY(fmha_policy_64x128x256);
#if defined(GPU_ARCH_XeHpc)
INSTANTIATE_POLICY(fmha_policy_64x256x256);
#if !(IMPL_KISTRAINING && IMPL_KISDROPOUT)
INSTANTIATE_POLICY(fmha_policy_64x128x512);
#endif
#endif
#endif
} // namespace fmha
} // namespace gpu::xetla
