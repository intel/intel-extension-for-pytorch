diff --git a/aten/src/ATen/SparseTensorImpl.cpp b/aten/src/ATen/SparseTensorImpl.cpp
index a735404..3bf11a6 100644
--- a/aten/src/ATen/SparseTensorImpl.cpp
+++ b/aten/src/ATen/SparseTensorImpl.cpp
@@ -9,6 +9,8 @@ namespace {
   DeviceType sparseTensorSetToDeviceType(DispatchKeySet key_set) {
     if (key_set.has(DispatchKey::SparseCPUTensorId)) {
       return kCPU;
+    } else if (key_set.has(DispatchKey::SparseDPCPPTensorId)) {
+      return kDPCPP;
     } else if (key_set.has(DispatchKey::SparseCUDATensorId)) {
       return kCUDA;
     } else {
diff --git a/aten/src/ATen/core/VariableFallbackKernel.cpp b/aten/src/ATen/core/VariableFallbackKernel.cpp
index 11d0349..3cb40c8 100644
--- a/aten/src/ATen/core/VariableFallbackKernel.cpp
+++ b/aten/src/ATen/core/VariableFallbackKernel.cpp
@@ -32,9 +32,9 @@ void variable_fallback_kernel(const OperatorHandle& op, Stack* stack) {
     Dispatcher::singleton().callBoxed(op, stack);
 }
 
-static auto registry = Dispatcher::singleton().registerBackendFallbackKernel(
-    DispatchKey::VariableTensorId,
-    KernelFunction::makeFromBoxedFunction<&variable_fallback_kernel>()
-);
+// static auto registry = Dispatcher::singleton().registerBackendFallbackKernel(
+//     DispatchKey::VariableTensorId,
+//     KernelFunction::makeFromBoxedFunction<&variable_fallback_kernel>()
+// );
 
 }
diff --git a/aten/src/ATen/native/sparse/SparseTensor.cpp b/aten/src/ATen/native/sparse/SparseTensor.cpp
index 8ce6045..ba7f79e 100644
--- a/aten/src/ATen/native/sparse/SparseTensor.cpp
+++ b/aten/src/ATen/native/sparse/SparseTensor.cpp
@@ -76,6 +76,8 @@ SparseTensor new_sparse(const TensorOptions& options) {
   DispatchKey dispatch_key;
   if (options.device().is_cuda()) {
     dispatch_key = DispatchKey::SparseCUDATensorId;
+  } else if (options.device().is_dpcpp()) {
+    dispatch_key = DispatchKey::SparseDPCPPTensorId;
   } else {
     dispatch_key = DispatchKey::SparseCPUTensorId;
   }
diff --git a/c10/core/Backend.h b/c10/core/Backend.h
index 5f3d8c7..a47240b 100644
--- a/c10/core/Backend.h
+++ b/c10/core/Backend.h
@@ -25,18 +25,22 @@ namespace c10 {
  * or "SparseCUDA"; backend in torch.backends is something like "MKL" or
  * "CUDNN".
  */
-enum class Backend { CPU, CUDA, HIP, SparseCPU, SparseCUDA, SparseHIP, MSNPU, XLA, QuantizedCPU, Undefined, MkldnnCPU, NumOptions };
+enum class Backend { CPU, CUDA, HIP, SparseCPU, SparseCUDA, SparseHIP, MSNPU, XLA, QuantizedCPU, Undefined, MkldnnCPU, DPCPP, SparseDPCPP, NumOptions };
 
 static inline Backend toSparse(Backend b) {
   switch (b) {
     case Backend::CPU:
       return Backend::SparseCPU;
+    case Backend::DPCPP:
+      return Backend::SparseDPCPP;
     case Backend::CUDA:
       return Backend::SparseCUDA;
     case Backend::HIP:
       return Backend::SparseHIP;
     case Backend::SparseCPU:
       return Backend::SparseCPU;
+    case Backend::SparseDPCPP:
+      return Backend::SparseDPCPP;
     case Backend::SparseCUDA:
       return Backend::SparseCUDA;
     case Backend::SparseHIP:
@@ -58,6 +62,10 @@ static inline Backend toDense(Backend b) {
       return Backend::MSNPU;
     case Backend::XLA:
       return Backend::XLA;
+    case Backend::DPCPP:
+      return Backend::DPCPP;
+    case Backend::SparseDPCPP:
+      return Backend::DPCPP;
     case Backend::SparseCPU:
       return Backend::CPU;
     case Backend::SparseCUDA:
@@ -82,6 +90,10 @@ static inline Backend dispatchKeyToBackend(DispatchKey t) {
     return Backend::MSNPU;
   } else if (t == DispatchKey::XLATensorId || t == DispatchKey::XLAPreAutograd) {
     return Backend::XLA;
+  } else if (t == DispatchKey::DPCPPTensorId) {
+    return Backend::DPCPP;
+  } else if (t == DispatchKey::SparseDPCPPTensorId) {
+    return Backend::SparseDPCPP;
   } else if (t == DispatchKey::SparseCPUTensorId) {
     return Backend::SparseCPU;
   } else if (t == DispatchKey::SparseCUDATensorId) {
@@ -111,6 +123,10 @@ static inline DispatchKey backendToDispatchKey(Backend b) {
       return DispatchKey::MSNPUTensorId;
     case Backend::XLA:
       return DispatchKey::XLATensorId;
+    case Backend::DPCPP:
+      return DispatchKey::DPCPPTensorId;
+    case Backend::SparseDPCPP:
+      return DispatchKey::SparseDPCPPTensorId;
     case Backend::SparseCPU:
       return DispatchKey::SparseCPUTensorId;
     case Backend::SparseCUDA:
@@ -146,6 +162,9 @@ static inline DeviceType backendToDeviceType(Backend b) {
       return DeviceType::CUDA;
     case Backend::SparseHIP:
       return DeviceType::HIP;
+    case Backend::DPCPP:
+    case Backend::SparseDPCPP:
+      return DeviceType::DPCPP;
     case Backend::MkldnnCPU:
     case Backend::QuantizedCPU:
       return DeviceType::CPU;
@@ -158,12 +177,14 @@ static inline DeviceType backendToDeviceType(Backend b) {
 
 static inline Backend backendToCPU(Backend b) {
   switch (b) {
+    case Backend::DPCPP:
     case Backend::CPU:
       return Backend::CPU;
     case Backend::CUDA:
       return Backend::CPU;
     case Backend::HIP:
       return Backend::CPU;
+    case Backend::SparseDPCPP:
     case Backend::SparseCPU:
       return Backend::SparseCPU;
     case Backend::SparseCUDA:
@@ -186,12 +207,14 @@ static inline Backend backendToCPU(Backend b) {
 
 static inline Backend backendToCUDA(Backend b) {
   switch (b) {
+    case Backend::DPCPP:
     case Backend::CPU:
     case Backend::CUDA:
     case Backend::HIP:
     case Backend::MSNPU:
     case Backend::XLA:
       return Backend::CUDA;
+    case Backend::SparseDPCPP:
     case Backend::SparseCPU:
     case Backend::SparseCUDA:
     case Backend::SparseHIP:
@@ -205,12 +228,14 @@ static inline Backend backendToCUDA(Backend b) {
 
 static inline Backend backendToHIP(Backend b) {
   switch (b) {
+    case Backend::DPCPP:
     case Backend::CPU:
     case Backend::CUDA:
     case Backend::HIP:
     case Backend::MSNPU:
     case Backend::XLA:
       return Backend::HIP;
+    case Backend::SparseDPCPP:
     case Backend::SparseCPU:
     case Backend::SparseCUDA:
     case Backend::SparseHIP:
@@ -225,6 +250,8 @@ static inline Backend backendToHIP(Backend b) {
 // TODO: This probably shouldn't actually be static inline
 static inline const char* toString(Backend b) {
   switch (b) {
+    case Backend::DPCPP:
+      return "DPCPP";
     case Backend::CPU:
       return "CPU";
     case Backend::CUDA:
@@ -235,6 +262,8 @@ static inline const char* toString(Backend b) {
       return "MSNPU";
     case Backend::XLA:
       return "XLA";
+    case Backend::SparseDPCPP:
+      return "SparseDPCPP";
     case Backend::SparseCPU:
       return "SparseCPU";
     case Backend::SparseCUDA:
@@ -252,6 +281,7 @@ static inline const char* toString(Backend b) {
 
 static inline bool isSparse(Backend b) {
   switch (b) {
+    case Backend::SparseDPCPP:
     case Backend::SparseCPU:
     case Backend::SparseCUDA:
     case Backend::SparseHIP:
diff --git a/c10/core/Device.cpp b/c10/core/Device.cpp
index 82a02fd..8268038 100644
--- a/c10/core/Device.cpp
+++ b/c10/core/Device.cpp
@@ -13,7 +13,7 @@
 namespace c10 {
 namespace {
 DeviceType parse_type(const std::string& device_string) {
-  static const std::array<std::pair<std::string, DeviceType>, 9> types = {{
+  static const std::array<std::pair<std::string, DeviceType>, 10> types = {{
       {"cpu", DeviceType::CPU},
       {"cuda", DeviceType::CUDA},
       {"mkldnn", DeviceType::MKLDNN},
@@ -23,6 +23,7 @@ DeviceType parse_type(const std::string& device_string) {
       {"hip", DeviceType::HIP},
       {"msnpu", DeviceType::MSNPU},
       {"xla", DeviceType::XLA},
+      {"dpcpp", DeviceType::DPCPP},
   }};
   auto device = std::find_if(
       types.begin(),
@@ -34,7 +35,7 @@ DeviceType parse_type(const std::string& device_string) {
     return device->second;
   }
   AT_ERROR(
-      "Expected one of cpu, cuda, mkldnn, opengl, opencl, ideep, hip, msnpu device type at start of device string: ", device_string);
+      "Expected one of cpu, cuda, mkldnn, opengl, opencl, ideep, dpcpp, hip, msnpu device type at start of device string: ", device_string);
 }
 } // namespace
 
diff --git a/c10/core/Device.h b/c10/core/Device.h
index f1249e8..31f15e8 100644
--- a/c10/core/Device.h
+++ b/c10/core/Device.h
@@ -86,6 +86,11 @@ struct C10_API Device final {
     return type_ == DeviceType::CPU;
   }
 
+  /// Return true if the device is of DPCPP type.
+  bool is_dpcpp() const noexcept {
+    return type_ == DeviceType::DPCPP;
+  }
+
   /// Same string as returned from operator<<.
   std::string str() const;
 
diff --git a/c10/core/DeviceType.cpp b/c10/core/DeviceType.cpp
index 017267c..486b02e 100644
--- a/c10/core/DeviceType.cpp
+++ b/c10/core/DeviceType.cpp
@@ -27,6 +27,8 @@ std::string DeviceTypeName(DeviceType d, bool lower_case) {
       return lower_case ? "msnpu" : "MSNPU";
     case DeviceType::XLA:
       return lower_case ? "xla" : "XLA";
+    case DeviceType::DPCPP:
+      return lower_case ? "dpcpp" : "DPCPP";
     default:
       AT_ERROR(
           "Unknown device: ",
@@ -59,6 +61,7 @@ bool isValidDeviceType(DeviceType d) {
     case DeviceType::FPGA:
     case DeviceType::MSNPU:
     case DeviceType::XLA:
+    case DeviceType::DPCPP:
       return true;
     default:
       return false;
diff --git a/c10/core/DeviceType.h b/c10/core/DeviceType.h
index 9f75966..23f6808 100644
--- a/c10/core/DeviceType.h
+++ b/c10/core/DeviceType.h
@@ -23,11 +23,12 @@ enum class DeviceType : int16_t {
   FPGA = 7, // FPGA
   MSNPU = 8, // MSNPU
   XLA = 9, // XLA / TPU
+  DPCPP = 10, // DPCPP
   // NB: If you add more devices:
   //  - Change the implementations of DeviceTypeName and isValidDeviceType
   //    in DeviceType.cpp
   //  - Change the number below
-  COMPILE_TIME_MAX_DEVICE_TYPES = 10,
+  COMPILE_TIME_MAX_DEVICE_TYPES = 11,
   ONLY_FOR_TEST = 20901, // This device type is only for test.
 };
 
@@ -36,6 +37,7 @@ constexpr DeviceType kCUDA = DeviceType::CUDA;
 constexpr DeviceType kHIP = DeviceType::HIP;
 constexpr DeviceType kMSNPU = DeviceType::MSNPU;
 constexpr DeviceType kXLA = DeviceType::XLA;
+constexpr DeviceType kDPCPP = DeviceType::DPCPP;
 
 // define explicit int constant
 constexpr int COMPILE_TIME_MAX_DEVICE_TYPES =
diff --git a/c10/core/DispatchKey.cpp b/c10/core/DispatchKey.cpp
index cf20e51..b093a64 100644
--- a/c10/core/DispatchKey.cpp
+++ b/c10/core/DispatchKey.cpp
@@ -36,6 +36,10 @@ const char* toString(DispatchKey t) {
       return "QuantizedCPUTensorId";
     case DispatchKey::VariableTensorId:
       return "VariableTensorId";
+    case DispatchKey::DPCPPTensorId:
+      return "DPCPPTensorId";
+    case DispatchKey::SparseDPCPPTensorId:
+      return "SparseDPCPPTensorId";
     case DispatchKey::BackendSelect:
       return "BackendSelect";
     case DispatchKey::TESTING_ONLY_GenericModeTensorId:
diff --git a/c10/core/DispatchKey.h b/c10/core/DispatchKey.h
index da7c3c5..1330c2b 100644
--- a/c10/core/DispatchKey.h
+++ b/c10/core/DispatchKey.h
@@ -90,6 +90,9 @@ enum class DispatchKey : uint8_t {
   SparseCUDATensorId, // registered at build/aten/src/ATen/SparseCUDAType.cpp
   SparseHIPTensorId,  // TODO: I think this is not actually used, due to Note [Masquerading as CUDA]
 
+  DPCPPTensorId, // DPCPP only
+  SparseDPCPPTensorId, // DPCPP only
+
   // Here are reserved backends for user-defined backends, see Note [Private use TensorId]
   // To see some example about how to use this, check out MSNPU
   PrivateUse1_TensorId,
diff --git a/c10/core/Layout.h b/c10/core/Layout.h
index c5ecc89..4aab440 100644
--- a/c10/core/Layout.h
+++ b/c10/core/Layout.h
@@ -15,6 +15,7 @@ constexpr auto kMkldnn = Layout::Mkldnn;
 inline Layout layout_from_backend(Backend backend) {
   switch (backend) {
     case Backend::SparseCPU:
+    case Backend::SparseDPCPP:
     case Backend::SparseCUDA:
     case Backend::SparseHIP:
       return Layout::Sparse;
diff --git a/c10/core/TensorImpl.h b/c10/core/TensorImpl.h
index de11b22..57513ae 100644
--- a/c10/core/TensorImpl.h
+++ b/c10/core/TensorImpl.h
@@ -425,7 +425,8 @@ struct C10_API TensorImpl : public c10::intrusive_ptr_target {
     // NB: This method is not virtual and avoid dispatches for performance reasons.
     return key_set_.has(DispatchKey::SparseCPUTensorId) ||
            key_set_.has(DispatchKey::SparseCUDATensorId) ||
-           key_set_.has(DispatchKey::SparseHIPTensorId);
+           key_set_.has(DispatchKey::SparseHIPTensorId) ||
+           key_set_.has(DispatchKey::SparseDPCPPTensorId);
   }
 
   bool is_quantized() const {
@@ -433,6 +434,11 @@ struct C10_API TensorImpl : public c10::intrusive_ptr_target {
     return key_set_.has(DispatchKey::QuantizedCPUTensorId);
   }
 
+  bool is_dpcpp() const {
+    return key_set_.has(DispatchKey::DPCPPTensorId) ||
+           key_set_.has(DispatchKey::SparseDPCPPTensorId);
+  }
+
   bool is_cuda() const {
     // NB: This method is not virtual and avoid dispatches for performance reasons.
     return key_set_.has(DispatchKey::CUDATensorId) ||
@@ -866,12 +872,14 @@ struct C10_API TensorImpl : public c10::intrusive_ptr_target {
     auto is_dense = [](DispatchKeySet ts) {
       return ts.has(DispatchKey::CPUTensorId) ||
              ts.has(DispatchKey::CUDATensorId) ||
-             ts.has(DispatchKey::HIPTensorId);
+             ts.has(DispatchKey::HIPTensorId) ||
+             ts.has(DispatchKey::DPCPPTensorId);
     };
     auto is_sparse = [](DispatchKeySet ts) {
       return ts.has(DispatchKey::SparseCPUTensorId) ||
              ts.has(DispatchKey::SparseCUDATensorId) ||
-             ts.has(DispatchKey::SparseHIPTensorId);
+             ts.has(DispatchKey::SparseHIPTensorId) ||
+             ts.has(DispatchKey::SparseDPCPPTensorId);
     };
     return (key_set_ == from) || (is_dense(key_set_) && is_dense(from)) || (is_sparse(key_set_) && is_sparse(from));
   }
diff --git a/c10/core/TensorOptions.h b/c10/core/TensorOptions.h
index 9a4c9b3..6d02405 100644
--- a/c10/core/TensorOptions.h
+++ b/c10/core/TensorOptions.h
@@ -398,6 +398,8 @@ struct C10_API TensorOptions {
             return DispatchKey::MSNPUTensorId;
           case DeviceType::XLA:
             return DispatchKey::XLATensorId;
+          case DeviceType::DPCPP:
+            return DispatchKey::DPCPPTensorId;
           default:
             AT_ERROR("Unsupported device type for dense layout: ", device().type());
         }
@@ -409,6 +411,8 @@ struct C10_API TensorOptions {
             return DispatchKey::SparseCUDATensorId;
           case DeviceType::HIP:
             return DispatchKey::SparseHIPTensorId;
+          case DeviceType::DPCPP:
+            return DispatchKey::SparseDPCPPTensorId;
           default:
             AT_ERROR("Unsupported device type for sparse layout: ", device().type());
         }
@@ -634,6 +638,10 @@ inline DeviceType computeDeviceType(DispatchKey tid) {
     return DeviceType::MSNPU;
   } else if (tid == DispatchKey::XLATensorId) {
     return DeviceType::XLA;
+  } else if (tid == DispatchKey::DPCPPTensorId) {
+    return DeviceType::DPCPP;
+  } else if (tid == DispatchKey::SparseDPCPPTensorId) {
+    return DeviceType::DPCPP;
   } else if (tid == DispatchKey::SparseCPUTensorId) {
     return DeviceType::CPU;
   } else if (tid == DispatchKey::SparseCUDATensorId) {
diff --git a/torch/csrc/utils/tensor_layouts.cpp b/torch/csrc/utils/tensor_layouts.cpp
index 6fcd84f..e42a7ba 100644
--- a/torch/csrc/utils/tensor_layouts.cpp
+++ b/torch/csrc/utils/tensor_layouts.cpp
@@ -23,6 +23,7 @@ void initializeLayouts() {
   registerLayoutObject((THPLayout*)strided_layout, at::Backend::CUDA);
   registerLayoutObject((THPLayout*)strided_layout, at::Backend::MSNPU);
   registerLayoutObject((THPLayout*)strided_layout, at::Backend::XLA);
+  registerLayoutObject((THPLayout*)strided_layout, at::Backend::DPCPP);
   registerLayoutObject((THPLayout*)strided_layout, at::Backend::QuantizedCPU);
 
   PyObject *sparse_coo_layout = THPLayout_New(at::Layout::Sparse, "torch.sparse_coo");
diff --git a/torch/csrc/utils/tensor_new.cpp b/torch/csrc/utils/tensor_new.cpp
index 85add73..ea90778 100644
--- a/torch/csrc/utils/tensor_new.cpp
+++ b/torch/csrc/utils/tensor_new.cpp
@@ -59,6 +59,8 @@ Backend backendToBackendOfDeviceType(Backend b, DeviceType d) {
     case DeviceType::XLA:
       TORCH_CHECK(!isSparse(b), "Sparse not implemented for XLA");
       return Backend::XLA;
+    case DeviceType::DPCPP:
+      return Backend::DPCPP;
     default:
       AT_ERROR("Unknown device type");
   }
@@ -333,6 +335,7 @@ Tensor legacy_new_from_sequence(
 void check_base_legacy_new(c10::DispatchKey dispatch_key, at::Layout expected_layout) {
   if (expected_layout == c10::kStrided) {
     TORCH_CHECK(dispatch_key == c10::DispatchKey::CPUTensorId
+                || dispatch_key == c10::DispatchKey::DPCPPTensorId
                 || dispatch_key == c10::DispatchKey::CUDATensorId
                 || dispatch_key == c10::DispatchKey::HIPTensorId
                 || dispatch_key == c10::XLATensorId(),
@@ -344,6 +347,7 @@ void check_base_legacy_new(c10::DispatchKey dispatch_key, at::Layout expected_la
   } else if(expected_layout == c10::kSparse) {
     // NOTE: no sparse XLA
     TORCH_CHECK(dispatch_key == c10::DispatchKey::SparseCPUTensorId
+                || dispatch_key == c10::DispatchKey::SparseDPCPPTensorId
                 || dispatch_key == c10::DispatchKey::SparseCUDATensorId
                 || dispatch_key == c10::DispatchKey::SparseHIPTensorId,
                 "new(): expected DispatchKey: ", c10::DispatchKey::SparseCPUTensorId,
diff --git a/torch/csrc/utils/tensor_types.cpp b/torch/csrc/utils/tensor_types.cpp
index e6b851a..3fa1a88 100644
--- a/torch/csrc/utils/tensor_types.cpp
+++ b/torch/csrc/utils/tensor_types.cpp
@@ -21,6 +21,8 @@ static const char* backend_to_string(const at::Backend& backend) {
     case at::Backend::CUDA: return "torch.cuda";
     case at::Backend::SparseCPU: return "torch.sparse";
     case at::Backend::SparseCUDA: return "torch.cuda.sparse";
+    case at::Backend::DPCPP: return "torch.dpcpp";
+    case at::Backend::SparseDPCPP: return "torch.dpcpp.sparse";
     default: AT_ERROR("Unimplemented backend ", backend);
   }
 }
