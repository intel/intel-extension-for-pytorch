From 28cf030d1ad5dcde5aae86a3546fd2ede47ed7f3 Mon Sep 17 00:00:00 2001
From: "Yu, Guangye" <106960996+guangyey@users.noreply.github.com>
Date: Fri, 21 Jun 2024 15:12:14 +0800
Subject: [PATCH 31/40] Enable deterministic support for oneDNN (#127277)
 (#264)

This PR is a part of RFC https://github.com/pytorch/pytorch/issues/114848.
For the request for Torchbenchmark models, this PR enables the deterministic attribute for the oneDNN operators for XPU backends, like convolution, deconvolution and matmult.

Pull Request resolved: https://github.com/pytorch/pytorch/pull/127277
Approved by: https://github.com/jgong5, https://github.com/EikanWang, https://github.com/desertfire, https://github.com/gujinghui

(cherry picked from commit b5428250668c48fd26e739a6cd6c0cd5d4c02659)

Co-authored-by: Deng Weishi <weishi.deng@intel.com>
---
 aten/src/ATen/Context.cpp         |  8 ++++++++
 aten/src/ATen/Context.h           |  3 +++
 benchmarks/dynamo/common.py       |  2 ++
 torch/_C/__init__.pyi.in          |  2 ++
 torch/backends/mkldnn/__init__.py | 19 +++++++++++--------
 torch/csrc/Module.cpp             | 27 +++++++++++++++++++++++++++
 6 files changed, 53 insertions(+), 8 deletions(-)

diff --git a/aten/src/ATen/Context.cpp b/aten/src/ATen/Context.cpp
index 9cd8244c6f9..0b2aa99cb0c 100644
--- a/aten/src/ATen/Context.cpp
+++ b/aten/src/ATen/Context.cpp
@@ -56,6 +56,14 @@ void Context::setDeterministicCuDNN(bool b) {
   deterministic_cudnn = b;
 }
 
+bool Context::deterministicMkldnn() const {
+  return deterministic_mkldnn;
+}
+
+void Context::setDeterministicMkldnn(bool b) {
+  deterministic_mkldnn = b;
+}
+
 bool Context::deterministicAlgorithms() const {
   return _deterministic_algorithms;
 }
diff --git a/aten/src/ATen/Context.h b/aten/src/ATen/Context.h
index 931cd86e77d..17910136ab0 100644
--- a/aten/src/ATen/Context.h
+++ b/aten/src/ATen/Context.h
@@ -179,6 +179,8 @@ class TORCH_API Context {
   void setBenchmarkLimitCuDNN(int);
   bool deterministicCuDNN() const;
   void setDeterministicCuDNN(bool);
+  bool deterministicMkldnn() const;
+  void setDeterministicMkldnn(bool);
   bool userEnabledNNPACK() const;
   void setUserEnabledNNPACK(bool e);
 
@@ -345,6 +347,7 @@ class TORCH_API Context {
   c10::once_flag thp_init;
   bool enabled_cudnn = true;
   bool deterministic_cudnn = false;
+  bool deterministic_mkldnn = false;
   bool _deterministic_algorithms = false;
   bool _deterministic_algorithms_warn_only = false;
   bool _deterministic_fill_uninitialized_memory = true;
diff --git a/benchmarks/dynamo/common.py b/benchmarks/dynamo/common.py
index 212392f4c4b..18c1bca7165 100644
--- a/benchmarks/dynamo/common.py
+++ b/benchmarks/dynamo/common.py
@@ -3523,6 +3523,8 @@ def run(runner, args, original_dir=None):
         torch.backends.cudnn.benchmark = False
         torch.backends.cuda.matmul.allow_tf32 = False
 
+        torch.backends.mkldnn.deterministic = True
+
         # Remove randomeness when torch manual seed is called
         patch_torch_manual_seed()
 
diff --git a/torch/_C/__init__.pyi.in b/torch/_C/__init__.pyi.in
index 3e05773349a..b4acf604a2e 100644
--- a/torch/_C/__init__.pyi.in
+++ b/torch/_C/__init__.pyi.in
@@ -1133,6 +1133,8 @@ def _get_cudnn_benchmark() -> _bool: ...  # THPModule_benchmarkCuDNN
 def _set_cudnn_benchmark(arg: _bool) -> None: ...  # THPModule_setBenchmarkCuDNN
 def _get_cudnn_deterministic() -> _bool: ...  # THPModule_deterministicCuDNN
 def _set_cudnn_deterministic(arg: _bool) -> None: ...  # THPModule_setDeterministicCuDNN
+def _get_mkldnn_deterministic() -> _bool: ...  # THPModule_deterministicMkldnn
+def _set_mkldnn_deterministic(arg: _bool) -> None: ...  # THPModule_setDeterministicMkldnn
 def _get_deterministic_algorithms() -> _bool: ...  # THPModule_deterministicAlgorithms
 def _get_deterministic_algorithms_warn_only() -> _bool: ...  # THPModule_deterministicAlgorithmsWarnOnly
 def _set_deterministic_algorithms(
diff --git a/torch/backends/mkldnn/__init__.py b/torch/backends/mkldnn/__init__.py
index 9cdee1cbd56..1dd87020661 100644
--- a/torch/backends/mkldnn/__init__.py
+++ b/torch/backends/mkldnn/__init__.py
@@ -64,21 +64,23 @@ class verbose:
         return False
 
 
-def set_flags(_enabled):
-    orig_flags = (torch._C._get_mkldnn_enabled(),)
+def set_flags(_enabled, _deterministic=None):
+    orig_flags = (torch._C._get_mkldnn_enabled(), torch._C._get_mkldnn_deterministic())
     torch._C._set_mkldnn_enabled(_enabled)
+    if _deterministic is not None:
+        torch._C._set_mkldnn_deterministic(_deterministic)
     return orig_flags
 
 
 @contextmanager
-def flags(enabled=False):
+def flags(enabled=False, deterministic=False):
     with __allow_nonbracketed_mutation():
-        orig_flags = set_flags(enabled)
+        orig_flags = set_flags(enabled, deterministic)
     try:
         yield
     finally:
         with __allow_nonbracketed_mutation():
-            set_flags(orig_flags[0])
+            set_flags(*orig_flags)
 
 
 class MkldnnModule(PropModule):
@@ -86,12 +88,13 @@ class MkldnnModule(PropModule):
         super().__init__(m, name)
 
     enabled = ContextProp(torch._C._get_mkldnn_enabled, torch._C._set_mkldnn_enabled)
+    deterministic = ContextProp(
+        torch._C._get_mkldnn_deterministic, torch._C._set_mkldnn_deterministic
+    )
 
 
 if TYPE_CHECKING:
     enabled: ContextProp
+    deterministic: ContextProp
 
-
-# Cool stuff from torch/backends/cudnn/__init__.py and
-# https://stackoverflow.com/questions/2447353/getattr-on-a-module/7668273#7668273
 sys.modules[__name__] = MkldnnModule(sys.modules[__name__], __name__)
diff --git a/torch/csrc/Module.cpp b/torch/csrc/Module.cpp
index 267cfcea27b..a7175c9c7b1 100644
--- a/torch/csrc/Module.cpp
+++ b/torch/csrc/Module.cpp
@@ -807,6 +807,25 @@ PyObject* THPModule_deterministicCuDNN(PyObject* _unused, PyObject* noargs) {
     Py_RETURN_FALSE;
 }
 
+PyObject* THPModule_setDeterministicMkldnn(PyObject* _unused, PyObject* arg) {
+  HANDLE_TH_ERRORS
+  TORCH_CHECK(
+      PyBool_Check(arg),
+      "set_deterministic_mkldnn expects a bool, "
+      "but got ",
+      THPUtils_typename(arg));
+  at::globalContext().setDeterministicMkldnn(arg == Py_True);
+  Py_RETURN_NONE;
+  END_HANDLE_TH_ERRORS
+}
+
+PyObject* THPModule_deterministicMkldnn(PyObject* _unused, PyObject* noargs) {
+  if (at::globalContext().deterministicMkldnn())
+    Py_RETURN_TRUE;
+  else
+    Py_RETURN_FALSE;
+}
+
 PyObject* THPModule_setDeterministicAlgorithms(
     PyObject* _unused,
     PyObject* args,
@@ -1339,6 +1358,14 @@ static PyMethodDef TorchMethods[] = { // NOLINT
      THPModule_setDeterministicCuDNN,
      METH_O,
      nullptr},
+    {"_get_mkldnn_deterministic",
+     THPModule_deterministicMkldnn,
+     METH_NOARGS,
+     nullptr},
+    {"_set_mkldnn_deterministic",
+     THPModule_setDeterministicMkldnn,
+     METH_O,
+     nullptr},
     {"_get_deterministic_algorithms",
      THPModule_deterministicAlgorithms,
      METH_NOARGS,
-- 
2.34.1

