Search.setIndex({"alltitles": {"1. Environment Setup": [[0, "environment-setup"]], "1.1 [RECOMMENDED] Docker-based environment setup with pre-built wheels": [[0, "recommended-docker-based-environment-setup-with-pre-built-wheels"]], "1.2 Conda-based environment setup with pre-built wheels": [[0, "conda-based-environment-setup-with-pre-built-wheels"]], "2. How To Run Phi 3 with ipex.llm": [[0, "how-to-run-phi-3-with-ipex-llm"]], "2.1 Usage of running Phi 3 models": [[0, "usage-of-running-phi-3-models"]], "2.1.1 Run generation with multiple instances on multiple CPU numa nodes": [[0, "run-generation-with-multiple-instances-on-multiple-cpu-numa-nodes"]], "2.1.1.1 Prepare:": [[0, "prepare"]], "2.1.1.2 BF16:": [[0, "bf16"]], "2.1.1.3 Weight-only quantization (INT8):": [[0, "weight-only-quantization-int8"]], "2.1.1.4 How to Shard Model weight files for Distributed Inference with DeepSpeed": [[0, "how-to-shard-model-weight-files-for-distributed-inference-with-deepspeed"]], "2.1.2 Run generation with single instance on a single numa node": [[0, "run-generation-with-single-instance-on-a-single-numa-node"]], "2.1.2.1 BF16:": [[0, "id1"]], "2.1.2.2 Weight-only quantization (INT8):": [[0, "id2"]], "2.1.2.3 Notes:": [[0, "notes"]], "Intel\u00ae Extension for PyTorch* Large Language Model (LLM) Feature Get Started For Phi 3 models": [[0, "intel-extension-for-pytorch-large-language-model-llm-feature-get-started-for-phi-3-models"]], "Miscellaneous Tips": [[0, "miscellaneous-tips"]]}, "docnames": ["index"], "envversion": {"sphinx": 61, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2}, "filenames": ["index.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"0": 0, "10": 0, "100": 0, "1024": 0, "130944": 0, "2048": 0, "32": 0, "4096": 0, "7": 0, "8192": 0, "A": 0, "And": 0, "By": 0, "If": 0, "In": 0, "OR": 0, "The": 0, "There": 0, "_": 0, "abov": 0, "access": 0, "accord": 0, "account": 0, "accuraci": 0, "activ": 0, "ad": 0, "advanc": 0, "after": 0, "all": 0, "alreadi": 0, "also": 0, "amp": 0, "an": 0, "ani": 0, "ar": 0, "arg": 0, "attent": 0, "auto": 0, "automat": 0, "autotp": 0, "avail": 0, "avoid": 0, "bash": 0, "batch": 0, "beam": 0, "befor": 0, "below": 0, "benchmark": 0, "besid": 0, "best": 0, "better": 0, "bfloat16": 0, "bind_cores_to_rank": 0, "both": 0, "build": 0, "c": 0, "can": 0, "case": 0, "cd": 0, "check": 0, "checkout": 0, "choos": 0, "clone": 0, "code": 0, "com": 0, "command": 0, "contain": 0, "control": 0, "copi": 0, "core": 0, "could": 0, "cover": 0, "creat": 0, "create_shard_model": 0, "data": 0, "dedic": 0, "default": 0, "detail": 0, "dir": 0, "directori": 0, "doc": 0, "docker_buildkit": 0, "dockerfil": 0, "download": 0, "dtype": 0, "e": 0, "either": 0, "enabl": 0, "enter": 0, "env": 0, "env_activ": 0, "env_setup": 0, "etc": 0, "even": 0, "exampl": 0, "f": 0, "facilit": 0, "fair": 0, "faster": 0, "first": 0, "fix": 0, "found": 0, "from": 0, "function": 0, "further": 0, "fusion": 0, "g": 0, "git": 0, "github": 0, "greedi": 0, "hardwar": 0, "have": 0, "help": 0, "home": 0, "http": 0, "huggingfac": 0, "i": 0, "id": 0, "imag": 0, "includ": 0, "inform": 0, "init": 0, "input": 0, "input_length": 0, "insid": 0, "instal": 0, "iter": 0, "json": 0, "kei": 0, "kmp_affin": 0, "latenc": 0, "later": 0, "launch": 0, "like": 0, "linux": 0, "list": 0, "llm_dir": 0, "local": 0, "local_phi3_model_shard": 0, "log": 0, "login": 0, "lscpu": 0, "m": 0, "mai": 0, "mani": 0, "max": 0, "memori": 0, "methodologi": 0, "mix": 0, "mode": 0, "more": 0, "n": 0, "name": 0, "need": 0, "new": 0, "next": 0, "num": 0, "numactl": 0, "omp_num_thread": 0, "ones": 0, "optim": 0, "other": 0, "out": 0, "output": 0, "page": 0, "path": 0, "peak": 0, "perform": 0, "phi3": 0, "phi3_model_id_or_local_path": 0, "phsysic": 0, "physic": 0, "placehold": 0, "pleas": 0, "point": 0, "prebuilt": 0, "precis": 0, "print": 0, "privileg": 0, "prompt": 0, "provid": 0, "pt": 0, "py": 0, "python": 0, "quant": 0, "recurs": 0, "refer": 0, "remov": 0, "repeat": 0, "replac": 0, "result": 0, "reus": 0, "rm": 0, "rope": 0, "sampl": 0, "save": 0, "saved_result": 0, "scenario": 0, "script": 0, "search": 0, "sec": 0, "section": 0, "set": 0, "sever": 0, "sh": 0, "show": 0, "size": 0, "skip": 0, "sourc": 0, "specifi": 0, "stage": 0, "standalon": 0, "step": 0, "stream": 0, "string": 0, "submodul": 0, "support": 0, "sync": 0, "t": 0, "task": 0, "technic": 0, "test": 0, "them": 0, "thi": 0, "token": 0, "tool": 0, "trigger": 0, "type": 0, "ubuntu": 0, "under": 0, "unset": 0, "updat": 0, "us": 0, "util": 0, "variabl": 0, "variou": 0, "warmup": 0, "we": 0, "well": 0, "when": 0, "which": 0, "won": 0, "work": 0, "would": 0, "y": 0, "you": 0, "your": 0}, "titles": ["Intel\u00ae Extension for PyTorch* Large Language Model (LLM) Feature Get Started For Phi 3 models"], "titleterms": {"1": 0, "2": 0, "3": 0, "4": 0, "For": 0, "To": 0, "base": 0, "bf16": 0, "built": 0, "conda": 0, "cpu": 0, "deepspe": 0, "distribut": 0, "docker": 0, "environ": 0, "extens": 0, "featur": 0, "file": 0, "gener": 0, "get": 0, "how": 0, "infer": 0, "instanc": 0, "int8": 0, "intel": 0, "ipex": 0, "languag": 0, "larg": 0, "llm": 0, "miscellan": 0, "model": 0, "multipl": 0, "node": 0, "note": 0, "numa": 0, "onli": 0, "phi": 0, "pre": 0, "prepar": 0, "pytorch": 0, "quantiz": 0, "recommend": 0, "run": 0, "setup": 0, "shard": 0, "singl": 0, "start": 0, "tip": 0, "usag": 0, "weight": 0, "wheel": 0}})